{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ramkuchana/RevisingConcepts/blob/master/Revising_computer_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08f47c6a-3318-4e3f-8bb3-c520e00e63dd",
      "metadata": {
        "id": "08f47c6a-3318-4e3f-8bb3-c520e00e63dd"
      },
      "source": [
        "# 03. PyTorch Computer Vision\n",
        "\n",
        "[Computer vision](https://en.wikipedia.org/wiki/Computer_vision) is the art of teaching a computer to see.\n",
        "\n",
        "For example, it could involve building a model to classify whether a photo is of a cat or a dog ([binary classification](https://developers.google.com/machine-learning/glossary#binary-classification)).\n",
        "\n",
        "Or whether a photo is of a cat, dog or chicken ([multi-class classification](https://developers.google.com/machine-learning/glossary#multi-class-classification)).\n",
        "\n",
        "Or identifying where a car appears in a video frame ([object detection](https://en.wikipedia.org/wiki/Object_detection)).\n",
        "\n",
        "Or figuring out where different objects in an image can be separated ([panoptic segmentation](https://arxiv.org/abs/1801.00868)).\n",
        "\n",
        "![example computer vision problems](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-computer-vision-problems.png)\n",
        "*Example computer vision problems for binary classification, multiclass classification, object detection and segmentation.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19179a39-0c6c-40f7-9891-09e17d107ecf",
      "metadata": {
        "id": "19179a39-0c6c-40f7-9891-09e17d107ecf"
      },
      "source": [
        "## Where does computer vision get used?\n",
        "\n",
        "If you use a smartphone, you've already used computer vision.\n",
        "\n",
        "Camera and photo apps use [computer vision to enhance](https://machinelearning.apple.com/research/panoptic-segmentation) and sort images.\n",
        "\n",
        "Modern cars use [computer vision](https://youtu.be/j0z4FweCy4M?t=2989) to avoid other cars and stay within lane lines.\n",
        "\n",
        "Manufacturers use computer vision to identify defects in various products.\n",
        "\n",
        "Security cameras use computer vision to detect potential intruders.\n",
        "\n",
        "In essence, anything that can described in a visual sense can be a potential computer vision problem."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "412e8bd1-0e6b-4ad6-8506-b28a8f669dc1",
      "metadata": {
        "id": "412e8bd1-0e6b-4ad6-8506-b28a8f669dc1"
      },
      "source": [
        "## What we're going to cover\n",
        "\n",
        "We're going to apply the PyTorch Workflow we've been learning in the past couple of sections to computer vision.\n",
        "\n",
        "![a PyTorch workflow with a computer vision focus](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-pytorch-computer-vision-workflow.png)\n",
        "\n",
        "Specifically, we're going to cover:\n",
        "\n",
        "| **Topic** | **Contents** |\n",
        "| ----- | ----- |\n",
        "| **0. Computer vision libraries in PyTorch** | PyTorch has a bunch of built-in helpful computer vision libraries, let's check them out.  |\n",
        "| **1. Load data** | To practice computer vision, we'll start with some images of different pieces of clothing from [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). |\n",
        "| **2. Prepare data** | We've got some images, let's load them in with a [PyTorch `DataLoader`](https://pytorch.org/docs/stable/data.html) so we can use them with our training loop. |\n",
        "| **3. Model 0: Building a baseline model** | Here we'll create a multi-class classification model to learn patterns in the data, we'll also choose a **loss function**, **optimizer** and build a **training loop**. |\n",
        "| **4. Making predictions and evaluting model 0** | Let's make some predictions with our baseline model and evaluate them. |\n",
        "| **5. Setup device agnostic code for future models** | It's best practice to write device-agnostic code, so let's set it up. |\n",
        "| **6. Model 1: Adding non-linearity** | Experimenting is a large part of machine learning, let's try and improve upon our baseline model by adding non-linear layers. |\n",
        "| **7. Model 2: Convolutional Neural Network (CNN)** | Time to get computer vision specific and introduce the powerful convolutional neural network architecture. |\n",
        "| **8. Comparing our models** | We've built three different models, let's compare them. |\n",
        "| **9. Evaluating our best model** | Let's make some predictons on random images and evaluate our best model. |\n",
        "| **10. Making a confusion matrix** | A confusion matrix is a great way to evaluate a classification model, let's see how we can make one. |\n",
        "| **11. Saving and loading the best performing model** | Since we might want to use our model for later, let's save it and make sure it loads back in correctly. |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cddf62c3-f5e5-4f7e-852a-2ad6d38b7399",
      "metadata": {
        "id": "cddf62c3-f5e5-4f7e-852a-2ad6d38b7399"
      },
      "source": [
        "## Where can can you get help?\n",
        "\n",
        "All of the materials for this course [live on GitHub](https://github.com/mrdbourke/pytorch-deep-learning).\n",
        "\n",
        "If you run into trouble, you can ask a question on the course [GitHub Discussions page](https://github.com/mrdbourke/pytorch-deep-learning/discussions) there too.\n",
        "\n",
        "And of course, there's the [PyTorch documentation](https://pytorch.org/docs/stable/index.html) and [PyTorch developer forums](https://discuss.pytorch.org/), a very helpful place for all things PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Computer vision libraries in PyTorch\n"
      ],
      "metadata": {
        "id": "qcSgLUvTar8z"
      },
      "id": "qcSgLUvTar8z"
    },
    {
      "cell_type": "markdown",
      "id": "a0bedcfc-e12a-4a81-9913-84c6a888742a",
      "metadata": {
        "id": "a0bedcfc-e12a-4a81-9913-84c6a888742a"
      },
      "source": [
        "\n",
        "Before we get started writing code, let's talk about some PyTorch computer vision libraries you should be aware of.\n",
        "\n",
        "| PyTorch module | What does it do? |\n",
        "| ----- | ----- |\n",
        "| [`torchvision`](https://pytorch.org/vision/stable/index.html) | Contains datasets, model architectures and image transformations often used for computer vision problems. |\n",
        "| [`torchvision.datasets`](https://pytorch.org/vision/stable/datasets.html) | Here you'll find many example computer vision datasets for a range of problems from image classification, object detection, image captioning, video classification and more. It also contains [a series of base classes for making custom datasets](https://pytorch.org/vision/stable/datasets.html#base-classes-for-custom-datasets). |\n",
        "| [`torchvision.models`](https://pytorch.org/vision/stable/models.html) | This module contains well-performing and commonly used computer vision model architectures implemented in PyTorch, you can use these with your own problems. |\n",
        "| [`torchvision.transforms`](https://pytorch.org/vision/stable/transforms.html) | Often images need to be transformed (turned into numbers/processed/augmented) before being used with a model, common image transformations are found here. |\n",
        "| [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) | Base dataset class for PyTorch.  |\n",
        "| [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#module-torch.utils.data) | Creates a Python iterable over a dataset (created with `torch.utils.data.Dataset`). |\n",
        "\n",
        "> **Note:** The `torch.utils.data.Dataset` and `torch.utils.data.DataLoader` classes aren't only for computer vision in PyTorch, they are capable of dealing with many different types of data.\n",
        "\n",
        "Now we've covered some of the most important PyTorch computer vision libraries, let's import the relevant dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c263a60d-d788-482f-b9e7-9cab4f6b1f72",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c263a60d-d788-482f-b9e7-9cab4f6b1f72",
        "outputId": "dc438ab3-d584-49ad-b503-9ebf7e09145f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.3.1+cu121\n",
            "torchvision version: 0.18.1+cu121\n"
          ]
        }
      ],
      "source": [
        "# Import PyTorch\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Import torchvision\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Import matplotlib for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check versions\n",
        "# Note: your PyTorch version shouldn't be lower than 1.10.0 and torchvision version shouldn't be lower than 0.11\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Getting a dataset\n"
      ],
      "metadata": {
        "id": "EL7R0SBoczaE"
      },
      "id": "EL7R0SBoczaE"
    },
    {
      "cell_type": "markdown",
      "id": "48d6bfe7-91da-44eb-9ab6-7c41c1e9fa8e",
      "metadata": {
        "id": "48d6bfe7-91da-44eb-9ab6-7c41c1e9fa8e"
      },
      "source": [
        "\n",
        "To begin working on a computer vision problem, let's get a computer vision dataset.\n",
        "\n",
        "We're going to start with FashionMNIST.\n",
        "\n",
        "MNIST stands for Modified National Institute of Standards and Technology.\n",
        "\n",
        "The [original MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database) contains thousands of examples of handwritten digits (from 0 to 9) and was used to build computer vision models to identify numbers for postal services.\n",
        "\n",
        "[FashionMNIST](https://github.com/zalandoresearch/fashion-mnist), made by Zalando Research, is a similar setup.\n",
        "\n",
        "Except it contains grayscale images of 10 different kinds of clothing.\n",
        "\n",
        "![example image of FashionMNIST](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-fashion-mnist-slide.png)\n",
        "*`torchvision.datasets` contains a lot of example datasets you can use to practice writing computer vision code on. FashionMNIST is one of those datasets. And since it has 10 different image classes (different types of clothing), it's a multi-class classification problem.*\n",
        "\n",
        "Later, we'll be building a computer vision neural network to identify the different styles of clothing in these images.\n",
        "\n",
        "PyTorch has a bunch of common computer vision datasets stored in `torchvision.datasets`.\n",
        "\n",
        "Including FashionMNIST in [`torchvision.datasets.FashionMNIST()`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html).\n",
        "\n",
        "To download it, we provide the following parameters:\n",
        "* `root: str` - which folder do you want to download the data to?\n",
        "* `train: Bool` - do you want the training or test split?\n",
        "* `download: Bool` - should the data be downloaded?\n",
        "* `transform: torchvision.transforms` - what transformations would you like to do on the data?\n",
        "* `target_transform` - you can transform the targets (labels) if you like too.\n",
        "\n",
        "Many other datasets in `torchvision` have these parameter options."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "486f8377-6810-4367-859d-69dccc7aef95",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "486f8377-6810-4367-859d-69dccc7aef95",
        "outputId": "78970325-b9d5-4c11-b778-b460275e8db1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 12765927.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 244183.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3745603.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 22191446.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Setup training data\n",
        "\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"data\", # where to download data to?\n",
        "    train=True, # get training data\n",
        "    download=True, # download data if it doesn't exist on disk\n",
        "    transform=ToTensor(), # images come as PIL format, we want to turn into Torch tensors\n",
        "    target_transform=None # want to transform labels ? No\n",
        ")\n",
        "\n",
        "\n",
        "# Setup testing data\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False, # to get test data\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a63246f6-3645-49de-88fe-ec18e78bfbaf",
      "metadata": {
        "id": "a63246f6-3645-49de-88fe-ec18e78bfbaf"
      },
      "source": [
        "Let's check out the first sample of the training data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_data)"
      ],
      "metadata": {
        "id": "SA3Ams2OiqEu",
        "outputId": "d8f9e0fd-7a8c-4737-e564-250a34c1d189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "id": "SA3Ams2OiqEu",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchvision.datasets.mnist.FashionMNIST"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torchvision.datasets.mnist.FashionMNIST</b><br/>def __init__(root: Union[str, Path], train: bool=True, transform: Optional[Callable]=None, target_transform: Optional[Callable]=None, download: bool=False) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py</a>`Fashion-MNIST &lt;https://github.com/zalandoresearch/fashion-mnist&gt;`_ Dataset.\n",
              "\n",
              "Args:\n",
              "    root (str or ``pathlib.Path``): Root directory of dataset where ``FashionMNIST/raw/train-images-idx3-ubyte``\n",
              "        and  ``FashionMNIST/raw/t10k-images-idx3-ubyte`` exist.\n",
              "    train (bool, optional): If True, creates dataset from ``train-images-idx3-ubyte``,\n",
              "        otherwise from ``t10k-images-idx3-ubyte``.\n",
              "    download (bool, optional): If True, downloads the dataset from the internet and\n",
              "        puts it in root directory. If dataset is already downloaded, it is not\n",
              "        downloaded again.\n",
              "    transform (callable, optional): A function/transform that  takes in a PIL image\n",
              "        and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
              "    target_transform (callable, optional): A function/transform that takes in the\n",
              "        target and transforms it.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 203);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "85wpNX5oi1qg",
        "outputId": "6ce1d46c-b0ce-44ae-8f1d-b5e2c91abf36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "85wpNX5oi1qg",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "metadata": {
        "id": "h-YV__Pafcjt",
        "outputId": "41b3e607-fb4a-4727-87fa-5fa9add5ed4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "h-YV__Pafcjt",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
              "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
              "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
              "           0.0157, 0.0000, 0.0000, 0.0118],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
              "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0471, 0.0392, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
              "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
              "           0.3020, 0.5098, 0.2824, 0.0588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
              "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
              "           0.5529, 0.3451, 0.6745, 0.2588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
              "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
              "           0.4824, 0.7686, 0.8980, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
              "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
              "           0.8745, 0.9608, 0.6784, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
              "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
              "           0.8627, 0.9529, 0.7922, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
              "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
              "           0.8863, 0.7725, 0.8196, 0.2039],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
              "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
              "           0.9608, 0.4667, 0.6549, 0.2196],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
              "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
              "           0.8510, 0.8196, 0.3608, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
              "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
              "           0.8549, 1.0000, 0.3020, 0.0000],\n",
              "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
              "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
              "           0.8784, 0.9569, 0.6235, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
              "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
              "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
              "           0.9137, 0.9333, 0.8431, 0.0000],\n",
              "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
              "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
              "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
              "           0.8627, 0.9098, 0.9647, 0.0000],\n",
              "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
              "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
              "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
              "           0.8706, 0.8941, 0.8824, 0.0000],\n",
              "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
              "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
              "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
              "           0.8745, 0.8784, 0.8980, 0.1137],\n",
              "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
              "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
              "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
              "           0.8627, 0.8667, 0.9020, 0.2627],\n",
              "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
              "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
              "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
              "           0.7098, 0.8039, 0.8078, 0.4510],\n",
              "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
              "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
              "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
              "           0.6549, 0.6941, 0.8235, 0.3608],\n",
              "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
              "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
              "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
              "           0.7529, 0.8471, 0.6667, 0.0000],\n",
              "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
              "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
              "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
              "           0.3882, 0.2275, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
              "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
              " 9)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_data[0])"
      ],
      "metadata": {
        "id": "jENWgGDjffS2",
        "outputId": "253f7b10-25b2-4d52-8716-0ade10cd5cd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "jENWgGDjffS2",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data[0])"
      ],
      "metadata": {
        "id": "vQCWFFs5fohh",
        "outputId": "f6b82234-a4dc-44da-a712-9449fc2d5ca8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "vQCWFFs5fohh",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_data[0][0])"
      ],
      "metadata": {
        "id": "EWprBmjNfjaO",
        "outputId": "0f88a7b6-24fa-40c9-9b6e-3b28fe4a3046",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "EWprBmjNfjaO",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_data[0][1])"
      ],
      "metadata": {
        "id": "8jWfp79CfmBo",
        "outputId": "14767536-4206-4133-e7cb-761369529df3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8jWfp79CfmBo",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "int"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "id": "VunMgb81gEG7",
        "outputId": "c6c76e47-015a-45df-c37d-1171988aee12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "VunMgb81gEG7",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "id": "eHdbCE7fgHGR",
        "outputId": "18da8d72-3a3d-4cf1-cc4c-51d98a4e0989",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "eHdbCE7fgHGR",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_data)"
      ],
      "metadata": {
        "id": "8q2nGALPgJ5Z",
        "outputId": "a9196389-e380-4c7c-8c50-46ffe877274c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8q2nGALPgJ5Z",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "43bfd3d9-a132-41e8-8ccd-5ae25a7da59a",
      "metadata": {
        "id": "43bfd3d9-a132-41e8-8ccd-5ae25a7da59a"
      },
      "outputs": [],
      "source": [
        "# See first training sample\n",
        "\n",
        "image, label = train_data[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label"
      ],
      "metadata": {
        "id": "Uka5TZq5iZf5",
        "outputId": "2f45dba5-7075-4753-f7db-8e6774265b92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Uka5TZq5iZf5",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "id": "kW7aU1gzibEW",
        "outputId": "918bbefe-9ae3-402f-d75a-0315d880d345",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "kW7aU1gzibEW",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['T-shirt/top',\n",
              " 'Trouser',\n",
              " 'Pullover',\n",
              " 'Dress',\n",
              " 'Coat',\n",
              " 'Sandal',\n",
              " 'Shirt',\n",
              " 'Sneaker',\n",
              " 'Bag',\n",
              " 'Ankle boot']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names[label]"
      ],
      "metadata": {
        "id": "04FRDvFui__a",
        "outputId": "e621ddab-0bde-49cd-ca3e-6371007c87f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "id": "04FRDvFui__a",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ankle boot'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_to_idx = train_data.class_to_idx\n",
        "\n",
        "class_to_idx"
      ],
      "metadata": {
        "id": "Ir9y2RlCjHKl",
        "outputId": "439c0fb4-83ef-4ccc-f3e4-0e8342bccc5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Ir9y2RlCjHKl",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'T-shirt/top': 0,\n",
              " 'Trouser': 1,\n",
              " 'Pullover': 2,\n",
              " 'Dress': 3,\n",
              " 'Coat': 4,\n",
              " 'Sandal': 5,\n",
              " 'Shirt': 6,\n",
              " 'Sneaker': 7,\n",
              " 'Bag': 8,\n",
              " 'Ankle boot': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Input and output shapes of a computer vision model\n"
      ],
      "metadata": {
        "id": "R08Sanl9jqQG"
      },
      "id": "R08Sanl9jqQG"
    },
    {
      "cell_type": "markdown",
      "id": "9ad9d782-06cb-4591-ae3c-3a8b2389a1b2",
      "metadata": {
        "id": "9ad9d782-06cb-4591-ae3c-3a8b2389a1b2"
      },
      "source": [
        "\n",
        "We've got a big tensor of values (the image) leading to a single value for the target (the label).\n",
        "\n",
        "Let's see the image shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "c2997d9f-b574-4d23-aa34-1a4df1751226",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2997d9f-b574-4d23-aa34-1a4df1751226",
        "outputId": "1ff0c0e4-f280-48b6-f598-26b07ef51b0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# What's the shape of the image?\n",
        "\n",
        "image.shape  # color, height, width  -- 1 color channel cuz its grey-scale image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5326a05-f807-448d-99a3-6d03fc8739f8",
      "metadata": {
        "id": "b5326a05-f807-448d-99a3-6d03fc8739f8"
      },
      "source": [
        "The shape of the image tensor is `[1, 28, 28]` or more specifically:\n",
        "\n",
        "```\n",
        "[color_channels=1, height=28, width=28]\n",
        "```\n",
        "\n",
        "Having `color_channels=1` means the image is grayscale.\n",
        "\n",
        "![example input and output shapes of the fashionMNIST problem](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-computer-vision-input-and-output-shapes.png)\n",
        "*Various problems will have various input and output shapes. But the premise remains: encode data into numbers, build a model to find patterns in those numbers, convert those patterns into something meaningful.*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If `color_channels=3`, the image comes in pixel values for red, green and blue (this is also known a the [RGB color model](https://en.wikipedia.org/wiki/RGB_color_model)).\n",
        "\n",
        "The order of our current tensor is often referred to as `CHW` (Color Channels, Height, Width).\n",
        "\n",
        "There's debate on whether images should be represented as `CHW` (color channels first) or `HWC` (color channels last).\n",
        "\n",
        "> **Note:** You'll also see `NCHW` and `NHWC` formats where `N` stands for *number of images*. For example if you have a `batch_size=32`, your tensor shape may be `[32, 1, 28, 28]`. We'll cover **batch sizes** later.\n",
        "\n"
      ],
      "metadata": {
        "id": "lhiBJEj1kGTJ"
      },
      "id": "lhiBJEj1kGTJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch generally accepts `NCHW` (channels first) as the default for many operators.\n",
        "\n",
        "However, PyTorch also explains that `NHWC` (channels last) performs better and is [considered best practice](https://pytorch.org/blog/tensor-memory-format-matters/#pytorch-best-practice).\n",
        "\n",
        "For now, since our dataset and models are relatively small, this won't make too much of a difference.\n",
        "\n",
        "But keep it in mind for when you're working on larger image datasets and using convolutional neural networks (we'll see these later).\n",
        "\n"
      ],
      "metadata": {
        "id": "qOe42_6fm51w"
      },
      "id": "qOe42_6fm51w"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check out more shapes of our data."
      ],
      "metadata": {
        "id": "qSXJmohLnI69"
      },
      "id": "qSXJmohLnI69"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "fc4f768c-c3f6-454d-a633-673ad1d6eca0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc4f768c-c3f6-454d-a633-673ad1d6eca0",
        "outputId": "90d0595c-c0e1-4b85-b048-c026658679d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 60000, 10000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# How many samples are there?\n",
        "\n",
        "len(train_data.data), len(train_data.targets), len(test_data.data), len(test_data.targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e0267d5-946b-4c53-af69-61acd3527972",
      "metadata": {
        "id": "6e0267d5-946b-4c53-af69-61acd3527972"
      },
      "source": [
        "So we've got 60,000 training samples and 10,000 testing samples.\n",
        "\n",
        "What classes are there?\n",
        "\n",
        "We can find these via the `.classes` attribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "e22849c6-d93f-4b38-8403-5ebf0deaf008",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e22849c6-d93f-4b38-8403-5ebf0deaf008",
        "outputId": "2902dcd3-9f9a-4c71-d28c-b4edecdfe7ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['T-shirt/top',\n",
              " 'Trouser',\n",
              " 'Pullover',\n",
              " 'Dress',\n",
              " 'Coat',\n",
              " 'Sandal',\n",
              " 'Shirt',\n",
              " 'Sneaker',\n",
              " 'Bag',\n",
              " 'Ankle boot']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# See classes\n",
        "class_names = train_data.classes\n",
        "class_names"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abdd225c-5742-4d9c-8e8d-fb30a9c3cb6e",
      "metadata": {
        "id": "abdd225c-5742-4d9c-8e8d-fb30a9c3cb6e"
      },
      "source": [
        "Sweet! It looks like we're dealing with 10 different kinds of clothes.\n",
        "\n",
        "Because we're working with 10 different classes, it means our problem is **multi-class classification**.\n",
        "\n",
        "Let's get visual."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb625d80-6a98-471e-a758-4de0ce0f3a64",
      "metadata": {
        "id": "fb625d80-6a98-471e-a758-4de0ce0f3a64"
      },
      "source": [
        "### 1.2 Visualizing our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "b1df1f2c-28c9-43bf-aaef-cf996c9ae1c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "b1df1f2c-28c9-43bf-aaef-cf996c9ae1c5",
        "outputId": "2db8c0b4-93a3-4e99-af36-f8adcb4f8d70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: torch.Size([1, 28, 28])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image, label = train_data[0]\n",
        "print(f\"Image shape: {image.shape}\")\n",
        "\n",
        "plt.imshow(image.squeeze()) # image shape is [1, 28, 28] (colour channels, height, width) ,squeezed to (28, 28)\n",
        "plt.title(label);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if you pass just image,\\\n",
        "i.e. plt.imshow(image)\n",
        "\n",
        "we get shape errors\n",
        "\n",
        "so this is one of those scenarios,\\\n",
        "where our data format so color channels first doesn't match up with what matplotlib is expecting\n",
        "\n",
        "so matplotlib expects either just height and width so no color channel for gray scale images\\\n",
        "or\\\n",
        "it also expects the color channels to be last so we'll see that later on."
      ],
      "metadata": {
        "id": "uSycMbDnnkEz"
      },
      "id": "uSycMbDnnkEz"
    },
    {
      "cell_type": "markdown",
      "id": "adb19c5c-2f2b-4aaf-8300-256f3594e2db",
      "metadata": {
        "id": "adb19c5c-2f2b-4aaf-8300-256f3594e2db"
      },
      "source": [
        "We can turn the image into grayscale using the `cmap` parameter of `plt.imshow()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "92f09917-88f7-4446-b65f-baae586914c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "92f09917-88f7-4446-b65f-baae586914c9",
        "outputId": "9318d897-5906-42e3-91b0-06d16843c52e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.imshow(image.squeeze(), cmap=\"gray\")\n",
        "\n",
        "plt.title(class_names[label]);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "in matplotlib \\\n",
        "if you ever have to change the colors of your plot you want\n",
        "to look into the 'cmap' parameter or sometimes parameter 'c'"
      ],
      "metadata": {
        "id": "AEfQfQI1odrj"
      },
      "id": "AEfQfQI1odrj"
    },
    {
      "cell_type": "markdown",
      "id": "9a09388a-d754-485f-aa26-4e7a0f782967",
      "metadata": {
        "id": "9a09388a-d754-485f-aa26-4e7a0f782967"
      },
      "source": [
        "Beautiful, well as beautiful as a pixelated grayscale ankle boot can get.\n",
        "\n",
        "Let's have a look at some random images from our data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "7188ed7a-5959-48c4-ac7f-19129a2adc83",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "id": "7188ed7a-5959-48c4-ac7f-19129a2adc83",
        "outputId": "90253434-40a0-4a1a-a36e-c1da499a2259"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x900 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot more random images\n",
        "\n",
        "torch.manual_seed(42)\n",
        "fig = plt.figure(figsize=(9, 9))\n",
        "\n",
        "rows, cols = 4, 4\n",
        "for i in range(1, rows * cols + 1):\n",
        "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
        "    img, label = train_data[random_idx]\n",
        "\n",
        "\n",
        "    fig.add_subplot(rows, cols, i)\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "    plt.title(class_names[label])\n",
        "    plt.axis(False);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f356fbe9-95b1-4f81-a82d-dc15b3adc06a",
      "metadata": {
        "id": "f356fbe9-95b1-4f81-a82d-dc15b3adc06a"
      },
      "source": [
        "Hmmm, this dataset doesn't look too aesthetic.\n",
        "\n",
        "But the principles we're going to learn on how to build a model for it will be similar across a wide range of computer vision problems.\n",
        "\n",
        "In essence, \\\n",
        "taking pixel values and building a model to find patterns in them to use on future pixel values.\n",
        "\n",
        "Plus, even for this small dataset (yes, even 60,000 images in deep learning is considered quite small), \\\n",
        "could you write a program to classify each one of them?\n",
        "\n",
        "You probably could.\n",
        "\n",
        "But I think coding a model in PyTorch would be faster.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:**\n",
        "\n",
        "Do you think the above data can be model with only straight (linear) lines?\\\n",
        "Or\\\n",
        "do you think you'd also need non-straight (non-linear) lines?"
      ],
      "metadata": {
        "id": "YISDBglcp-3A"
      },
      "id": "YISDBglcp-3A"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Prepare DataLoader\n"
      ],
      "metadata": {
        "id": "rrp1Y_GeqDMR"
      },
      "id": "rrp1Y_GeqDMR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Right now,\\\n",
        "our data (training_data, testing_data) is in the form of PyTorch Datasets.\n",
        "\n",
        "\n",
        "DataLoader turns our data set into a python iterable\n",
        "\n",
        "More specifically,\\\n",
        "we want to turn our data into batches or mini batches"
      ],
      "metadata": {
        "id": "L8pBJhDpqRv2"
      },
      "id": "L8pBJhDpqRv2"
    },
    {
      "cell_type": "markdown",
      "id": "43cdd23d-bd1f-4e8c-ba20-22d2b6ac14b1",
      "metadata": {
        "id": "43cdd23d-bd1f-4e8c-ba20-22d2b6ac14b1"
      },
      "source": [
        "\n",
        "Now we've got a dataset ready to go.\n",
        "\n",
        "The next step is to prepare it with a [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) or `DataLoader` for short.\n",
        "\n",
        "The `DataLoader` does what you think it might do.\n",
        "\n",
        "It helps load data into a model.\n",
        "\n",
        "For training and for inference.\n",
        "\n",
        "It turns a large `Dataset` into a Python iterable of smaller chunks.\n",
        "\n",
        "These smaller chunks are called **batches** or **mini-batches** and can be set by the `batch_size` parameter.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why do this?\n",
        "\n",
        "Because it's more computationally efficient.\n",
        "\n",
        "if our computer hardware was able to look at 60 000 samples of 28 by 28 at one time, chances are that it might not be able to store millions of images in memory and also CPU or GPU might not be able to look all images in one hit\n",
        "\n",
        "so what you do is you break a data set from say 60 000 into groups of batches or mini batches.\n",
        "\n",
        "In an ideal world you could do the forward pass and backward pass across all of your data at once.\n",
        "\n",
        "But once you start using really large datasets,\\\n",
        "unless you've got infinite computing power, it's easier to break them up into batches.\n",
        "\n",
        "It also gives your model more opportunities to improve.\n",
        "\n",
        "With **mini-batches** (small portions of the data),\\\n",
        "gradient descent is performed more often per epoch (once per mini-batch rather than once per epoch)."
      ],
      "metadata": {
        "id": "awLJst7cq6el"
      },
      "id": "awLJst7cq6el"
    },
    {
      "cell_type": "markdown",
      "source": [
        "What's a good batch size?\n",
        "\n",
        "[32 is a good place to start](https://twitter.com/ylecun/status/989610208497360896?s=20&t=N96J_jotN--PYuJk2WcjMw) for a fair amount of problems.\n",
        "\n",
        "But since this is a value you can set (a **hyperparameter**) you can try all different kinds of values, \\\n",
        "though generally powers of 2 are used most often (e.g. 32, 64, 128, 256, 512).\n",
        "\n",
        "![an example of what a batched dataset looks like](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-batching-fashionmnist.png)\n",
        "*Batching FashionMNIST with a batch size of 32 and shuffle turned on. A similar batching process will occur for other datasets but will differ depending on the batch size.*\n",
        "\n"
      ],
      "metadata": {
        "id": "pJkH5XIgs2fJ"
      },
      "id": "pJkH5XIgs2fJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create `DataLoader`'s for our training and test sets."
      ],
      "metadata": {
        "id": "uPQibQ5cs4nX"
      },
      "id": "uPQibQ5cs4nX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "this principle of preparing a data loader goes the same for not only images but for text for audio whatever sort of data you're working with\n",
        "\n",
        "mini batches will follow you along or batches of data will follow you along throughout a lot of different deep learning problems"
      ],
      "metadata": {
        "id": "Jebzzt45tv3G"
      },
      "id": "Jebzzt45tv3G"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "bb2dbf90-a326-43cb-b25b-71af142fafeb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb2dbf90-a326-43cb-b25b-71af142fafeb",
        "outputId": "43a6e4e9-6354-44ee-e46e-1acd81d967ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataloader: <torch.utils.data.dataloader.DataLoader object at 0x78c67c7c7970>\n",
            "Test Dataloader: <torch.utils.data.dataloader.DataLoader object at 0x78c67c7c79a0>\n",
            "\n",
            "Length of train dataloader: 1875 batches of 32\n",
            "Length of test dataloader: 313 batches of 32\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Setup the batch size hyperparameter\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Turn datasets into iterables (batches)\n",
        "train_dataloader = DataLoader(train_data, # dataset to turn into iterable\n",
        "    batch_size=BATCH_SIZE, # how many samples per batch?\n",
        "    shuffle=True # shuffle data every epoch?\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(test_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False # don't necessarily have to shuffle the testing data cuz  we are not training\n",
        ")\n",
        "\n",
        "# Let's check out what we've created\n",
        "print(f\"Train Dataloader: {train_dataloader}\")\n",
        "print(f\"Test Dataloader: {test_dataloader}\", end ='\\n\\n')\n",
        "\n",
        "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\") # 60000 / 32\n",
        "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\") # 10000 / 32\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this means that our model is going to look at 1875 individual batches of 32 images rather than just one big batch of 60 000 images\n",
        "\n",
        "now of course the number of batches we have will change if we change the batch size"
      ],
      "metadata": {
        "id": "9Nv9Cz1bvnTO"
      },
      "id": "9Nv9Cz1bvnTO"
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_dataloader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "jd7upNejA7o9",
        "outputId": "a12ce040-b707-4028-b792-2dc1304268fa"
      },
      "id": "jd7upNejA7o9",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataloader.DataLoader"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torch.utils.data.dataloader.DataLoader</b><br/>def __init__(dataset: Dataset[T_co], batch_size: Optional[int]=1, shuffle: Optional[bool]=None, sampler: Union[Sampler, Iterable, None]=None, batch_sampler: Union[Sampler[List], Iterable[List], None]=None, num_workers: int=0, collate_fn: Optional[_collate_fn_t]=None, pin_memory: bool=False, drop_last: bool=False, timeout: float=0, worker_init_fn: Optional[_worker_init_fn_t]=None, multiprocessing_context=None, generator=None, *, prefetch_factor: Optional[int]=None, persistent_workers: bool=False, pin_memory_device: str=&#x27;&#x27;)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py</a>Data loader combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
              "\n",
              "The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
              "iterable-style datasets with single- or multi-process loading, customizing\n",
              "loading order and optional automatic batching (collation) and memory pinning.\n",
              "\n",
              "See :py:mod:`torch.utils.data` documentation page for more details.\n",
              "\n",
              "Args:\n",
              "    dataset (Dataset): dataset from which to load the data.\n",
              "    batch_size (int, optional): how many samples per batch to load\n",
              "        (default: ``1``).\n",
              "    shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
              "        at every epoch (default: ``False``).\n",
              "    sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
              "        samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
              "        implemented. If specified, :attr:`shuffle` must not be specified.\n",
              "    batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
              "        returns a batch of indices at a time. Mutually exclusive with\n",
              "        :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
              "        and :attr:`drop_last`.\n",
              "    num_workers (int, optional): how many subprocesses to use for data\n",
              "        loading. ``0`` means that the data will be loaded in the main process.\n",
              "        (default: ``0``)\n",
              "    collate_fn (Callable, optional): merges a list of samples to form a\n",
              "        mini-batch of Tensor(s).  Used when using batched loading from a\n",
              "        map-style dataset.\n",
              "    pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
              "        into device/CUDA pinned memory before returning them.  If your data elements\n",
              "        are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
              "        see the example below.\n",
              "    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
              "        if the dataset size is not divisible by the batch size. If ``False`` and\n",
              "        the size of dataset is not divisible by the batch size, then the last batch\n",
              "        will be smaller. (default: ``False``)\n",
              "    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
              "        from workers. Should always be non-negative. (default: ``0``)\n",
              "    worker_init_fn (Callable, optional): If not ``None``, this will be called on each\n",
              "        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
              "        input, after seeding and before data loading. (default: ``None``)\n",
              "    multiprocessing_context (str or multiprocessing.context.BaseContext, optional): If\n",
              "        ``None``, the default `multiprocessing context`_ of your operating system will\n",
              "        be used. (default: ``None``)\n",
              "    generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
              "        by RandomSampler to generate random indexes and multiprocessing to generate\n",
              "        ``base_seed`` for workers. (default: ``None``)\n",
              "    prefetch_factor (int, optional, keyword-only arg): Number of batches loaded\n",
              "        in advance by each worker. ``2`` means there will be a total of\n",
              "        2 * num_workers batches prefetched across all workers. (default value depends\n",
              "        on the set value for num_workers. If value of num_workers=0 default is ``None``.\n",
              "        Otherwise, if value of ``num_workers &gt; 0`` default is ``2``).\n",
              "    persistent_workers (bool, optional): If ``True``, the data loader will not shut down\n",
              "        the worker processes after a dataset has been consumed once. This allows to\n",
              "        maintain the workers `Dataset` instances alive. (default: ``False``)\n",
              "    pin_memory_device (str, optional): the device to :attr:`pin_memory` to if ``pin_memory`` is\n",
              "        ``True``.\n",
              "\n",
              "\n",
              ".. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
              "             cannot be an unpicklable object, e.g., a lambda function. See\n",
              "             :ref:`multiprocessing-best-practices` on more details related\n",
              "             to multiprocessing in PyTorch.\n",
              "\n",
              ".. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
              "             When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
              "             it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
              "             rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
              "             configurations. This represents the best guess PyTorch can make because PyTorch\n",
              "             trusts user :attr:`dataset` code in correctly handling multi-process\n",
              "             loading to avoid duplicate data.\n",
              "\n",
              "             However, if sharding results in multiple workers having incomplete last batches,\n",
              "             this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
              "             be broken into multiple ones and (2) more than one batch worth of samples can be\n",
              "             dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
              "             cases in general.\n",
              "\n",
              "             See `Dataset Types`_ for more details on these two types of datasets and how\n",
              "             :class:`~torch.utils.data.IterableDataset` interacts with\n",
              "             `Multi-process data loading`_.\n",
              "\n",
              ".. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
              "             :ref:`data-loading-randomness` notes for random seed related questions.\n",
              "\n",
              ".. _multiprocessing context:\n",
              "    https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 124);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "so because our data loader provides an iterable over the given dataset\n",
        "and here we have 1875 batches of 32\n",
        "\n",
        "we're going to turn the train_dataloader object into an iterable with iter \\\n",
        "and we're going to get the next batch with next"
      ],
      "metadata": {
        "id": "CoHpeNLbBb_N"
      },
      "id": "CoHpeNLbBb_N"
    },
    {
      "cell_type": "code",
      "source": [
        "type(next(iter(train_dataloader)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bjfs2QoUA-tt",
        "outputId": "0a5b2b97-bc4c-4db6-ccf1-e9391aef2aa2"
      },
      "id": "Bjfs2QoUA-tt",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(next(iter(train_dataloader)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXXEVaiABD91",
        "outputId": "a949137f-f1ca-488a-9474-fe5b0acd19fd"
      },
      "id": "nXXEVaiABD91",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "7a925ee7-484b-4149-be8f-3ad790172a5f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a925ee7-484b-4149-be8f-3ad790172a5f",
        "outputId": "78ddd9ec-7e9e-4415-a873-0e1d6c4d53f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Check out what's inside the training dataloader\n",
        "\n",
        "train_features_batch, train_labels_batch = next(iter(train_dataloader)) # features = images and labels = target\n",
        "\n",
        "train_features_batch.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "color channels came first"
      ],
      "metadata": {
        "id": "Dy1b8DAHCDlj"
      },
      "id": "Dy1b8DAHCDlj"
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnUamCnyB7eL",
        "outputId": "496eaee1-9609-44b6-cdbe-d901f73a1723"
      },
      "id": "XnUamCnyB7eL",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fee4cf8-ab73-4c81-8e5e-3c81691e799c",
      "metadata": {
        "id": "4fee4cf8-ab73-4c81-8e5e-3c81691e799c"
      },
      "source": [
        "And we can see that the data remains unchanged by checking a single sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "c863d66a-49be-43be-84dc-372a5d6fc2c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "c863d66a-49be-43be-84dc-372a5d6fc2c2",
        "outputId": "f3f2433d-3c70-405c-d305-4fc8e246b97b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size: torch.Size([1, 28, 28])\n",
            "Label: 6, label size: torch.Size([])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Show a sample image\n",
        "\n",
        "torch.manual_seed(42)\n",
        "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
        "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
        "\n",
        "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.title(class_names[label])\n",
        "plt.axis(\"Off\"); # or False\n",
        "\n",
        "print(f\"Image size: {img.shape}\")\n",
        "print(f\"Label: {label}, label size: {label.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Model 0: Build a baseline model\n"
      ],
      "metadata": {
        "id": "m0y-cxSMCaYa"
      },
      "id": "m0y-cxSMCaYa"
    },
    {
      "cell_type": "markdown",
      "id": "db1695cf-f53d-4c7c-ad39-dfed76533125",
      "metadata": {
        "id": "db1695cf-f53d-4c7c-ad39-dfed76533125"
      },
      "source": [
        "\n",
        "Data loaded and prepared!\n",
        "\n",
        "Time to build a **baseline model** by subclassing `nn.Module`.\n",
        "\n",
        "A **baseline model** is one of the simplest models you can imagine.\n",
        "\n",
        "You use the baseline as a starting point and try to improve upon it with subsequent, more complicated models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our baseline will consist of two [`nn.Linear()`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) layers.\n",
        "\n",
        "We've done this in a previous section but there's going to one slight difference.\n",
        "\n",
        "Because we're working with image data, we're going to use a different layer to start things off.\n",
        "\n",
        "And that's the [`nn.Flatten()`](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html) layer.\n",
        "\n",
        "`nn.Flatten()` compresses the dimensions of a tensor into a single vector.\n",
        "\n",
        "This is easier to understand when you see it."
      ],
      "metadata": {
        "id": "7dwyi6rOCesE"
      },
      "id": "7dwyi6rOCesE"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "405319f1-f242-4bd9-90f5-3abdc50782ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "405319f1-f242-4bd9-90f5-3abdc50782ac",
        "outputId": "0b5e11d3-5288-4fd7-954e-49e14eb0a287"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# Create a flatten layer\n",
        "\n",
        "flatten_model = nn.Flatten() # all nn modules function as a model thats y we named flatten_model (can do a forward pass)\n",
        "\n",
        "\n",
        "# Get a single sample from the batch we created\n",
        "\n",
        "x = train_features_batch[0]\n",
        "\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Flatten the sample\n",
        "output = flatten_model(x) # performs forward pass internally\n",
        "\n",
        "# Print out what happened\n",
        "print(f\"Shape before flattening: {x.shape} -> [color_channels, height, width]\")\n",
        "print(f\"Shape after flattening: {output.shape} -> [color_channels, height*width]\")\n",
        "\n",
        "# Try uncommenting below and see what happens\n",
        "#print(x)\n",
        "#print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEytPMIpDgt-",
        "outputId": "c62207f2-a176-43cd-f0bb-0801098e6d90"
      },
      "id": "yEytPMIpDgt-",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape before flattening: torch.Size([1, 28, 28]) -> [color_channels, height, width]\n",
            "Shape after flattening: torch.Size([1, 784]) -> [color_channels, height*width]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "why might we do this?\n",
        "\n",
        "\n",
        "well it's because we're going to build a baseline model \\\n",
        "and we're going to use a linear layer as the baseline model \\\n",
        "and the linear layer can't handle multi-dimensional data like this (28 * 28) \\\n",
        "we want it to have a single vector as input (784)"
      ],
      "metadata": {
        "id": "DrSsLFNMEfb3"
      },
      "id": "DrSsLFNMEfb3"
    },
    {
      "cell_type": "markdown",
      "id": "86bb7806-fca6-45af-8111-3e00e38f5be9",
      "metadata": {
        "id": "86bb7806-fca6-45af-8111-3e00e38f5be9"
      },
      "source": [
        "The `nn.Flatten()` layer took our shape from `[color_channels, height, width]` to `[color_channels, height*width]`.\n",
        "\n",
        "Why do this?\n",
        "\n",
        "Because we've now turned our pixel data from height and width dimensions into one long **feature vector**.\n",
        "\n",
        "And `nn.Linear()` layers like their inputs to be in the form of feature vectors.\n",
        "\n",
        "Let's create our first model using `nn.Flatten()` as the first layer.\n",
        "\n",
        "the flattened layer has **NO** learnable parameters \\\n",
        "only these nn.Linear layers have\n",
        "\n",
        "\n",
        "and we have NO non-linearities \\\n",
        "so do you think this will work does our data set need non-linearities \\\n",
        "well we can find out once we fit our model to the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "1449f427-6859-41ae-8133-50b58ffbce72",
      "metadata": {
        "id": "1449f427-6859-41ae-8133-50b58ffbce72"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class FashionMNISTModelV0(nn.Module):\n",
        "\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "\n",
        "        super().__init__()\n",
        "        self.layer_stack = nn.Sequential(\n",
        "            nn.Flatten(), # neural networks like their inputs in vector form, so this method flattens the data into single vector\n",
        "            nn.Linear(in_features=input_shape, out_features=hidden_units), # in_features = number of features in a data sample (784 pixels)\n",
        "            nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer_stack(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d1b50bf-d00b-485c-be00-b3e4de156fab",
      "metadata": {
        "id": "4d1b50bf-d00b-485c-be00-b3e4de156fab"
      },
      "source": [
        "Wonderful!\n",
        "\n",
        "We've got a baseline model class we can use, now let's instantiate a model.\n",
        "\n",
        "We'll need to set the following parameters:\n",
        "* `input_shape=784` - this is how many features you've got going in the model, in our case, it's one for every pixel in the target image (28 pixels high by 28 pixels wide = 784 features).\n",
        "* `hidden_units=10` - number of units/neurons in the hidden layer(s), this number could be whatever you want but to keep the model small we'll start with `10`.\n",
        "* `output_shape=len(class_names)` - since we're working with a multi-class classification problem, we need an output neuron per class in our dataset.\n",
        "\n",
        "Let's create an instance of our model and send to the CPU for now (we'll run a small test for running `model_0` on CPU vs. a similar model on GPU soon)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "dd18384a-76f9-4b5a-a013-fda077f16865",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd18384a-76f9-4b5a-a013-fda077f16865",
        "outputId": "e49a1f59-94a8-4cd7-8a6d-96522c86eb12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FashionMNISTModelV0(\n",
              "  (layer_stack): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
              "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Need to setup model with input parameters\n",
        "\n",
        "model_0 = FashionMNISTModelV0(input_shape=784, #  (28x28) - one for every pixel\n",
        "                              hidden_units=10, # how many units in the hiden layer\n",
        "                              output_shape=len(class_names) # one for every class\n",
        "                              )\n",
        "\n",
        "\n",
        "model_0.to(\"cpu\") # keep model on CPU to begin with"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can try and do a dummy forward pass and see what happens\n",
        "\n",
        "\n",
        "\n",
        "so this is going to send dummy x through the forward method\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4XpSWwVoJx1O"
      },
      "id": "4XpSWwVoJx1O"
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_x = torch.rand([1,1,28,28]) # batch size, color, height, width\n",
        "\n",
        "\n",
        "model_0(dummy_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnEV-aMmJ-u5",
        "outputId": "f58d0e8f-f04f-49e5-95fa-e0de4bb48622"
      },
      "id": "YnEV-aMmJ-u5",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0315,  0.3171,  0.0531, -0.2525,  0.5959,  0.2112,  0.3233,  0.2694,\n",
              "         -0.1004,  0.0157]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_0(dummy_x).shape  # we have 10 classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQqT0YUgKqmz",
        "outputId": "82c97358-03df-417f-8e5e-6d0cdedffcd4"
      },
      "id": "zQqT0YUgKqmz",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see values going thru and everything is working as expected\n",
        "\n",
        "\n",
        "this is a great way to troubleshoot to see if your model shapes are correct\n",
        "\n",
        "if they come out correctly and if the inputs are lining up with where they need to be"
      ],
      "metadata": {
        "id": "KE0fYaCrJ_GA"
      },
      "id": "KE0fYaCrJ_GA"
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vq6jwrmwLvRo",
        "outputId": "cc79acf6-45fa-403c-cae4-82ea642cb4f1"
      },
      "id": "vq6jwrmwLvRo",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('layer_stack.1.weight',\n",
              "              tensor([[ 0.0273,  0.0296, -0.0084,  ..., -0.0142,  0.0093,  0.0135],\n",
              "                      [-0.0188, -0.0354,  0.0187,  ..., -0.0106, -0.0001,  0.0115],\n",
              "                      [-0.0008,  0.0017,  0.0045,  ..., -0.0127, -0.0188,  0.0059],\n",
              "                      ...,\n",
              "                      [-0.0116,  0.0273, -0.0344,  ...,  0.0176,  0.0283, -0.0011],\n",
              "                      [-0.0230,  0.0257,  0.0291,  ..., -0.0187, -0.0087,  0.0001],\n",
              "                      [ 0.0176, -0.0147,  0.0053,  ..., -0.0336, -0.0221,  0.0205]])),\n",
              "             ('layer_stack.1.bias',\n",
              "              tensor([-0.0093,  0.0283, -0.0033,  0.0255,  0.0017,  0.0037, -0.0302, -0.0123,\n",
              "                       0.0018,  0.0163])),\n",
              "             ('layer_stack.2.weight',\n",
              "              tensor([[ 0.0614, -0.0687,  0.0021,  0.2718,  0.2109,  0.1079, -0.2279, -0.1063,\n",
              "                        0.2019,  0.2847],\n",
              "                      [-0.1495,  0.1344, -0.0740,  0.2006, -0.0475, -0.2514, -0.3130, -0.0118,\n",
              "                        0.0932, -0.1864],\n",
              "                      [ 0.2488,  0.1500,  0.1907,  0.1457, -0.3050, -0.0580,  0.1643,  0.1565,\n",
              "                       -0.2877, -0.1792],\n",
              "                      [ 0.2305, -0.2618,  0.2397, -0.0610,  0.0232,  0.1542,  0.0851, -0.2027,\n",
              "                        0.1030, -0.2715],\n",
              "                      [-0.1596, -0.0555, -0.0633,  0.2302, -0.1726,  0.2654,  0.1473,  0.1029,\n",
              "                        0.2252, -0.2160],\n",
              "                      [-0.2725,  0.0118,  0.1559,  0.1596,  0.0132,  0.3024,  0.1124,  0.1366,\n",
              "                       -0.1533,  0.0965],\n",
              "                      [-0.1184, -0.2555, -0.2057, -0.1909, -0.0477, -0.1324,  0.2905,  0.1307,\n",
              "                       -0.2629,  0.0133],\n",
              "                      [ 0.2727, -0.0127,  0.0513,  0.0863, -0.1043, -0.2047, -0.1185, -0.0825,\n",
              "                        0.2488, -0.2571],\n",
              "                      [ 0.0425, -0.1209, -0.0336, -0.0281, -0.1227,  0.0730,  0.0747, -0.1816,\n",
              "                        0.1943,  0.2853],\n",
              "                      [-0.1310,  0.0645, -0.1171,  0.2168, -0.0245, -0.2820,  0.0736,  0.2621,\n",
              "                        0.0012, -0.0810]])),\n",
              "             ('layer_stack.2.bias',\n",
              "              tensor([-0.0087,  0.1791,  0.2712, -0.0791,  0.1685,  0.1762,  0.2825,  0.2266,\n",
              "                      -0.2612, -0.2613]))])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "feature in data:  \n",
        "feature in data could be almost anything\n",
        "\n",
        "so for example the feature of this bag could be that it's got a rounded handle at the top it has a edge over here it has an edge over there now\n",
        "\n",
        "we aren't going to tell our model what features to learn about the data the whole premise of it is to or the whole fun the whole magic behind machine learning is that it figures out what features to learn and so that is what the weights and bias matrices or tensors will represent there's different features in our images\n",
        "\n"
      ],
      "metadata": {
        "id": "czp_NpSfMFTN"
      },
      "id": "czp_NpSfMFTN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Setup loss, optimizer and evaluation metrics\n"
      ],
      "metadata": {
        "id": "NpWscWihJj_K"
      },
      "id": "NpWscWihJj_K"
    },
    {
      "cell_type": "markdown",
      "id": "03243179-1cdc-45d9-8b8c-82538ac02e9c",
      "metadata": {
        "id": "03243179-1cdc-45d9-8b8c-82538ac02e9c"
      },
      "source": [
        "\n",
        "Since we're working on a classification problem, let's bring in our [`helper_functions.py` script](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/helper_functions.py) \\\n",
        "and subsequently the `accuracy_fn()` we defined in [notebook 02](https://www.learnpytorch.io/02_pytorch_classification/).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> **Note:** Rather than importing and using our own accuracy function or evaluation metric(s), you could import various evaluation metrics from the [TorchMetrics package](https://torchmetrics.readthedocs.io/en/latest/)."
      ],
      "metadata": {
        "id": "z_8xVHlMJq44"
      },
      "id": "z_8xVHlMJq44"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "31c91f17-d810-46a4-97c3-c734f93430b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31c91f17-d810-46a4-97c3-c734f93430b1",
        "outputId": "3364fce6-97b0-44c5-9532-a6cc94925b95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading helper_functions.py\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"helper_functions.py already exists, skipping download\")\n",
        "else:\n",
        "  print(\"Downloading helper_functions.py\")\n",
        "  # Note: you need the \"raw\" GitHub URL for this to work\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    f.write(request.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "ce3d13b8-f018-4b44-8bba-375074dc4c5f",
      "metadata": {
        "id": "ce3d13b8-f018-4b44-8bba-375074dc4c5f"
      },
      "outputs": [],
      "source": [
        "# Import accuracy metric\n",
        "\n",
        "from helper_functions import accuracy_fn # Note: could also use torchmetrics.Accuracy(task = 'multiclass', num_classes=len(class_names)).to(device)\n",
        "\n",
        "# Setup loss function and optimizer\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss() # cuz we have multi-class data, this is also called \"criterion\"/\"cost function\" in some places\n",
        "\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4109f867-83f2-4394-a925-8acdc63ccffe",
      "metadata": {
        "id": "4109f867-83f2-4394-a925-8acdc63ccffe"
      },
      "source": [
        "### 3.2 Creating a function to time our experiments\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "machine learning is very experimental two of the main things you'll often want to track are\n",
        "\n",
        "1. your model's performance such as its loss and accuracy values etc\n",
        "\n",
        "  and\n",
        "\n",
        "2. how fast it runs\n",
        "\n",
        "\n",
        "how fast it runs will really be important  \n",
        "if you're running a model say on the internet or say on a dedicated gpu or say on a mobile device\n",
        "\n"
      ],
      "metadata": {
        "id": "pyM2k2DdU-uk"
      },
      "id": "pyM2k2DdU-uk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss function and optimizer ready!\n",
        "\n",
        "It's time to start training a model.\n",
        "\n",
        "But how about we do a little experiment while we train.\n",
        "\n",
        "I mean, let's make a timing function to measure the time it takes our model to train on CPU versus using a GPU.\n",
        "\n",
        "We'll train this model on the CPU but the next one on the GPU and see what happens.\n",
        "\n",
        "\n",
        "Our timing function will import the [`timeit.default_timer()` function](https://docs.python.org/3/library/timeit.html#timeit.default_timer) from the Python [`timeit` module](https://docs.python.org/3/library/timeit.html).\n",
        "\n",
        "`timeit.default_timer()` function \\\n",
        "purpose is : this is the exact time that our code started and then we're going to create another stop for when our code stopped and then we're going to compare the start and stop times\n",
        "\n",
        "\n",
        "you can read about more time it functions in the **time it** module"
      ],
      "metadata": {
        "id": "MMLGE1ioP6Qx"
      },
      "id": "MMLGE1ioP6Qx"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "31adc3fe-ce90-4b4e-b0d4-3613abae5714",
      "metadata": {
        "id": "31adc3fe-ce90-4b4e-b0d4-3613abae5714"
      },
      "outputs": [],
      "source": [
        "\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "def print_train_time(start: float, end: float, device: torch.device = None):\n",
        "    \"\"\"Prints difference between start and end time.\n",
        "\n",
        "    Args:\n",
        "        start (float): Start time of computation (preferred in timeit format).\n",
        "        end (float): End time of computation.\n",
        "        device ([type], optional): Device that compute is running on. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        float: time between start and end in seconds (higher is longer).\n",
        "    \"\"\"\n",
        "    total_time = end - start\n",
        "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
        "    return total_time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Creating a training loop and training a model on batches of data\n"
      ],
      "metadata": {
        "id": "wgMXefdEQGN_"
      },
      "id": "wgMXefdEQGN_"
    },
    {
      "cell_type": "markdown",
      "id": "07b9560e-f5dc-45d6-b3b2-ddae17a71b34",
      "metadata": {
        "id": "07b9560e-f5dc-45d6-b3b2-ddae17a71b34"
      },
      "source": [
        "\n",
        "Beautiful!\n",
        "\n",
        "Looks like we've got all of the pieces of the puzzle ready to go, a timer, a loss function, an optimizer, a model and most importantly, some data.\n",
        "\n",
        "Let's now create a training loop and a testing loop to train and evaluate our model.\n",
        "\n",
        "We'll be using the same steps as the previous notebook(s),\n",
        "though since our data is now in **batch form**,\n",
        "we'll add another loop to loop through our data batches.\n",
        "\n",
        "Our data batches are contained within our `DataLoader`,\\\n",
        " `train_dataloader` and `test_dataloader` for the training and test data splits respectively.\n",
        "\n",
        "A batch is `BATCH_SIZE` samples of `X` (features) and `y` (labels), since we're using `BATCH_SIZE=32`, our batches have 32 samples of images and targets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And since we're computing on batches of data, our loss and evaluation metrics will be calculated **per batch** rather than across the whole dataset.\n",
        "\n",
        "This means we'll have to divide our loss and accuracy values by the number of batches in each dataset's respective dataloader.\n",
        "\n",
        "Let's step through it:\n",
        "1. Loop through epochs.\n",
        "2. Loop through training batches, perform training steps, calculate the train loss *per batch*.\n",
        "3. Loop through testing batches, perform testing steps, calculate the test loss *per batch*.\n",
        "4. Print out what's happening.\n",
        "5. Time it all (for fun).\n",
        "\n",
        "A fair few steps but...\n",
        "\n",
        "...if in doubt, code it out."
      ],
      "metadata": {
        "id": "ZdefwHtyWn4p"
      },
      "id": "ZdefwHtyWn4p"
    },
    {
      "cell_type": "markdown",
      "source": [
        "tqdm\n",
        "\n",
        "tqdm.auto is just going to recognize what compute environment we're using and it's going to give us the best type of progress bar for what we're doing\n",
        "\n",
        "so for example google collab is running a jupyter notebook behind the scenes so the progress bar for jupyter notebooks is a little bit different to python scripts\n"
      ],
      "metadata": {
        "id": "ZWdZL6XoW-go"
      },
      "id": "ZWdZL6XoW-go"
    },
    {
      "cell_type": "markdown",
      "source": [
        "in the beginning\n",
        "when you're running experiments you want them to run quite quickly \\\n",
        "so that you can run them more often so you can learn more about your data \\\n",
        "so that you can try different things try different models \\\n",
        "so this is why we're using number of epochs = 3 and we have small dataset"
      ],
      "metadata": {
        "id": "kZklLYG1YFBw"
      },
      "id": "kZklLYG1YFBw"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "c07bbf10-81e3-47f0-990d-9a4a838276ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587,
          "referenced_widgets": [
            "91a4ae15fca94112998a102bbadab183",
            "d5672ef5a4dd4341b5cbfd0a70981e57",
            "f717e46a25fe49b1b95d18b6fc8d9a19",
            "9048827e1faf4a36bdd27c65d2c13583",
            "6e071c51293a4bce87d86f5ee58266f5",
            "5b643e4b479d4791b7d6b536a0474c23",
            "30191705727c45c8bb8b5ea49fc0bc62",
            "cd38b144c0e14821aa8f77a201ccd980",
            "45f81dd710214e839bb813c30b990d08",
            "6f235274904143a0872b5747c78114c8",
            "fc5efe6c6e16471cb282ed2c401d6fdb"
          ]
        },
        "id": "c07bbf10-81e3-47f0-990d-9a4a838276ab",
        "outputId": "0e0ea6f1-7871-4877-d69f-e5d328f627f2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91a4ae15fca94112998a102bbadab183"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "-------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n",
            "\n",
            "Train loss: 0.59039 | Test loss: 0.50954, Test acc: 82.04%\n",
            "\n",
            "Epoch: 1\n",
            "-------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n",
            "\n",
            "Train loss: 0.47633 | Test loss: 0.47989, Test acc: 83.20%\n",
            "\n",
            "Epoch: 2\n",
            "-------\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n",
            "\n",
            "Train loss: 0.45503 | Test loss: 0.47664, Test acc: 83.43%\n",
            "\n",
            "Train time on cpu: 42.340 seconds\n"
          ]
        }
      ],
      "source": [
        "# Import tqdm for progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Set the seed and start the timer\n",
        "torch.manual_seed(42)\n",
        "train_time_start_on_cpu = timer() # starts the timer\n",
        "\n",
        "\n",
        "# Set the number of epochs (we'll keep this small for faster training times)\n",
        "epochs = 3\n",
        "\n",
        "# Create training and testing loop\n",
        "\n",
        "for epoch in tqdm(range(epochs)): # wrap our iterator with tqdm\n",
        "\n",
        "    print(f\"Epoch: {epoch}\\n-------\")\n",
        "\n",
        "    ### Training\n",
        "\n",
        "    train_loss = 0\n",
        "\n",
        "    # Add a loop to loop through training BATCHES i.e. Batch loop not Epoch loop\n",
        "\n",
        "    for batch, (X, y) in enumerate(train_dataloader):  # features - X , labels - y\n",
        "\n",
        "        model_0.train() # its default but we explicitly mention to be clear here\n",
        "\n",
        "        # 1. Forward pass\n",
        "        y_pred = model_0(X)\n",
        "\n",
        "        # 2. Calculate loss (per batch)\n",
        "\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss # accumulative train loss i.e. add up the loss per epoch\n",
        "\n",
        "        # 3. Optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Loss backward\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print out how many samples have been seen\n",
        "\n",
        "        if batch % 400 == 0:\n",
        "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
        "\n",
        "    # Divide total train loss by length of train dataloader (average loss per batch per epoch)\n",
        "\n",
        "    # Epoch loop -  we are outside of Batch loop here\n",
        "\n",
        "    train_loss /= len(train_dataloader)\n",
        "\n",
        "    ### Testing\n",
        "\n",
        "    # Setup variables for accumulatively adding up loss and accuracy\n",
        "\n",
        "    test_loss, test_acc = 0, 0\n",
        "\n",
        "    model_0.eval()\n",
        "    with torch.inference_mode():\n",
        "\n",
        "        for X, y in test_dataloader:\n",
        "\n",
        "            # 1. Forward pass\n",
        "            test_pred = model_0(X) # gives out logits\n",
        "\n",
        "            # 2. Calculate loss (accumatively)\n",
        "            test_loss += loss_fn(test_pred, y) # accumulatively add up the loss per epoch\n",
        "\n",
        "            # 3. Calculate accuracy (preds need to be same as y_true)\n",
        "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))  # labes to labels comparision possible cuz of argmax\n",
        "\n",
        "        # Calculations on test metrics need to happen inside torch.inference_mode()\n",
        "\n",
        "        # Divide total test loss by length of test dataloader (per batch)\n",
        "\n",
        "        test_loss /= len(test_dataloader)\n",
        "\n",
        "        # Divide total accuracy by length of test dataloader (per batch)\n",
        "\n",
        "        test_acc /= len(test_dataloader)\n",
        "\n",
        "    ## Print out what's happening\n",
        "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n",
        "\n",
        "# Calculate training time\n",
        "train_time_end_on_cpu = timer() # End timer\n",
        "\n",
        "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu,\n",
        "                                           end=train_time_end_on_cpu,\n",
        "                                           device=str(next(model_0.parameters()).device))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b02a939-a3a1-4a9d-bb9d-62928def2ded",
      "metadata": {
        "id": "7b02a939-a3a1-4a9d-bb9d-62928def2ded"
      },
      "source": [
        "Nice! Looks like our baseline model did fairly well.\n",
        "\n",
        "It didn't take too long to train either, even just on the CPU, I wonder if it'll speed up on the GPU?\n",
        "\n",
        "Let's write some code to evaluate our model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Make predictions and get Model 0 results\n"
      ],
      "metadata": {
        "id": "j2DBGQYsQKNZ"
      },
      "id": "j2DBGQYsQKNZ"
    },
    {
      "cell_type": "markdown",
      "id": "7442511b-bfe9-4ec7-9f5b-9c808f8e560b",
      "metadata": {
        "id": "7442511b-bfe9-4ec7-9f5b-9c808f8e560b"
      },
      "source": [
        "\n",
        "Since we're going to be building a few models, it's a good idea to write some code to evaluate them all in similar ways.\n",
        "\n",
        "Namely, let's create a function that takes in a trained model, a `DataLoader`, a loss function and an accuracy function.\n",
        "\n",
        "The function will use the model to make predictions on the data in the `DataLoader` and then we can evaluate those predictions using the loss function and accuracy function."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this is going to be much the same as our testing loop above except it's going to be functionalized and we're going to return a dictionary"
      ],
      "metadata": {
        "id": "ObQ70ZNQbkJy"
      },
      "id": "ObQ70ZNQbkJy"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "8317dd04-9de2-4fd7-97bd-1e202621397d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8317dd04-9de2-4fd7-97bd-1e202621397d",
        "outputId": "fc5eeda2-27eb-4327-bfd6-8ecd977d5644"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_name': 'FashionMNISTModelV0',\n",
              " 'model_loss': 0.47663888335227966,\n",
              " 'model_acc': 83.42651757188499}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "def eval_model(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn):\n",
        "\n",
        "    \"\"\"Returns a dictionary containing the results of model predicting on data_loader.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.\n",
        "        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.\n",
        "        loss_fn (torch.nn.Module): The loss function of model.\n",
        "        accuracy_fn: An accuracy function to compare the models predictions to the truth labels.\n",
        "\n",
        "    Returns:\n",
        "        (dict): Results of model making predictions on data_loader.\n",
        "    \"\"\"\n",
        "    loss, acc = 0, 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X, y in data_loader: # we can also add tqdm here\n",
        "\n",
        "            # Make predictions with the model\n",
        "            y_pred = model(X)\n",
        "\n",
        "            # Accumulate the loss and accuracy values per batch\n",
        "\n",
        "            loss += loss_fn(y_pred, y)\n",
        "            acc += accuracy_fn(y_true=y,\n",
        "                                y_pred=y_pred.argmax(dim=1)) # For accuracy, need the prediction labels (logits -> pred_prob -> pred_labels)\n",
        "\n",
        "        # Scale loss and acc to find the average loss/acc per batch\n",
        "\n",
        "        loss /= len(data_loader)\n",
        "        acc /= len(data_loader)\n",
        "\n",
        "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
        "            \"model_loss\": loss.item(), # single value of python datatype\n",
        "            \"model_acc\": acc}\n",
        "\n",
        "# Calculate model 0 results on test dataset\n",
        "model_0_results = eval_model(model=model_0, data_loader=test_dataloader,\n",
        "    loss_fn=loss_fn, accuracy_fn=accuracy_fn\n",
        ")\n",
        "\n",
        "model_0_results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "you see how we could reuse this dictionary later on\n",
        "\n",
        "so if we had model 1 results model 2 results \\\n",
        "we could use these dictionaries and compare them all together"
      ],
      "metadata": {
        "id": "_yl3CRTUcadB"
      },
      "id": "_yl3CRTUcadB"
    },
    {
      "cell_type": "markdown",
      "id": "a39c3042-1262-4d1f-b33e-c8e2ba6781d3",
      "metadata": {
        "id": "a39c3042-1262-4d1f-b33e-c8e2ba6781d3"
      },
      "source": [
        "Looking good!\n",
        "\n",
        "We can use this dictionary to compare the baseline model results to other models later on."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Setup device agnostic-code (for using a GPU if there is one)"
      ],
      "metadata": {
        "id": "wt2V80rwcjbT"
      },
      "id": "wt2V80rwcjbT"
    },
    {
      "cell_type": "markdown",
      "id": "3b76784d-4cdb-43d2-a6da-8e4da9a812a9",
      "metadata": {
        "id": "3b76784d-4cdb-43d2-a6da-8e4da9a812a9"
      },
      "source": [
        "\n",
        "We've seen how long it takes to train ma PyTorch model on 60,000 samples on CPU.\n",
        "\n",
        "> **Note:** Model training time is dependent on hardware used. Generally, more processors means faster training and smaller models on smaller datasets will often train faster than large models and large datasets.\n",
        "\n",
        "Now let's setup some [device-agnostic code](https://pytorch.org/docs/stable/notes/cuda.html#best-practices) for our models and data to run on GPU if it's available.\n",
        "\n",
        "If you're running this notebook on Google Colab, and you don't a GPU turned on yet, it's now time to turn one on via `Runtime -> Change runtime type -> Hardware accelerator -> GPU`. If you do this, your runtime will likely reset and you'll have to run all of the cells above by going `Runtime -> Run before`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "17b69fe9-f974-4538-922c-20c5cc8220cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "17b69fe9-f974-4538-922c-20c5cc8220cc",
        "outputId": "bdf8a22d-59be-4ba6-f8e6-a18dff6f8c68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# Setup device agnostic code\n",
        "\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "514021a8-d6f2-47f3-ab50-55f844e42310",
      "metadata": {
        "id": "514021a8-d6f2-47f3-ab50-55f844e42310"
      },
      "source": [
        "Beautiful!\n",
        "\n",
        "Let's build another model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "i asked the question before\n",
        "\n",
        "\n",
        "do you think that the data set that we're working with requires non-linearity so the shirts and the bags and the shoes do we need non-linear functions to model this\n",
        "\n",
        "well it looks like our baseline model without non-linearities did pretty well at modeling our data so i've got a pretty good test accuracy value 83 %\n",
        "so 83 so out of 100 images\n",
        "\n",
        "lets see what happens if we add non-linearity\n"
      ],
      "metadata": {
        "id": "h8W3VIu3dC7z"
      },
      "id": "h8W3VIu3dC7z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "so here we are at 6th step in our typical workflow of PyTorch\n",
        "\n",
        "\n",
        "we're up to improving through experimentation \\\n",
        "and quite often that is building a different model and trying it out \\\n",
        "it could be using more data it could be tweaking a whole bunch of different things etc\n"
      ],
      "metadata": {
        "id": "qEMuY-RWdfkv"
      },
      "id": "qEMuY-RWdfkv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Model 1: Building a better model with non-linearity\n"
      ],
      "metadata": {
        "id": "2YCF6giOchSV"
      },
      "id": "2YCF6giOchSV"
    },
    {
      "cell_type": "markdown",
      "id": "d7893907-5f82-4c5e-8fde-fa542a9f25af",
      "metadata": {
        "id": "d7893907-5f82-4c5e-8fde-fa542a9f25af"
      },
      "source": [
        "\n",
        "We learned about [the power of non-linearity in notebook 02](https://www.learnpytorch.io/02_pytorch_classification/#6-the-missing-piece-non-linearity).\n",
        "\n",
        "Seeing the data we've been working with, do you think it needs non-linear functions?\n",
        "\n",
        "And remember, linear means straight and non-linear means non-straight.\n",
        "\n",
        "Let's find out.\n",
        "\n",
        "We'll do so by recreating a similar model to before, \\\n",
        "except this time we'll put non-linear functions (`nn.ReLU()`) in between each linear layer.\n",
        "\n",
        "we could try it just with one nonlinear activation \\\n",
        "but lets see with two Relus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "2ccce5f2-b1e5-47a6-a7f3-6bc096b35ffb",
      "metadata": {
        "id": "2ccce5f2-b1e5-47a6-a7f3-6bc096b35ffb"
      },
      "outputs": [],
      "source": [
        "# Create a model with non-linear and linear layers\n",
        "\n",
        "class FashionMNISTModelV1(nn.Module):\n",
        "\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "\n",
        "        super().__init__()\n",
        "        self.layer_stack = nn.Sequential(\n",
        "            nn.Flatten(), # flatten inputs into single vector\n",
        "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        return self.layer_stack(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b4b7a2f-4834-4aa1-a8e2-b6e3e2b49224",
      "metadata": {
        "id": "4b4b7a2f-4834-4aa1-a8e2-b6e3e2b49224"
      },
      "source": [
        "That looks good.\n",
        "\n",
        "Now let's instantiate it with the same settings we used before.\n",
        "\n",
        "We'll need `input_shape=784` (equal to the number of features of our image data), `hidden_units=10` (starting small and the same as our baseline model) and `output_shape=len(class_names)` (one output unit per class).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** Notice how we kept most of the settings of our model the same except for one change: adding non-linear layers.\n",
        "\n",
        "This is a standard practice for running a series of machine learning **experiments**,\\\n",
        "change one thing and see what happens, then do it again, again, again.\n"
      ],
      "metadata": {
        "id": "1Vi_HU3BeIAD"
      },
      "id": "1Vi_HU3BeIAD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "that's a thing to keep a note for your experiments when you're running fair few experiments you only really want to tweak a couple of things or maybe just one thing per experiment that way you can really narrow down what actually influences your model and what improves it / what doesn't improve it"
      ],
      "metadata": {
        "id": "9MxNrD8UfGfH"
      },
      "id": "9MxNrD8UfGfH"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "907091ec-7e46-470b-a305-788a3009b837",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "907091ec-7e46-470b-a305-788a3009b837",
        "outputId": "05eeb61e-b5d2-45b7-abc8-1cdd27f6f8a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "model_1 = FashionMNISTModelV1(input_shape=784, # number of input features after flattening\n",
        "                              hidden_units=10,\n",
        "                              output_shape=len(class_names) # number of output classes desired\n",
        "                              ).to(device) # send model to GPU if it's available\n",
        "\n",
        "next(model_1.parameters()).device # check model device\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 Setup loss, optimizer and evaluation metrics\n"
      ],
      "metadata": {
        "id": "VFWc9Y2_eyf6"
      },
      "id": "VFWc9Y2_eyf6"
    },
    {
      "cell_type": "markdown",
      "id": "b54a4e9d-a7ad-404c-920f-485fcff18a92",
      "metadata": {
        "id": "b54a4e9d-a7ad-404c-920f-485fcff18a92"
      },
      "source": [
        "\n",
        "As usual, we'll setup a loss function, an optimizer and an evaluation metric (we could do multiple evaluation metrics but we'll stick with accuracy for now)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "fe7e463b-d46c-4f00-853c-fdf0a28d74c8",
      "metadata": {
        "id": "fe7e463b-d46c-4f00-853c-fdf0a28d74c8"
      },
      "outputs": [],
      "source": [
        "from helper_functions import accuracy_fn\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss() # since multi-class data\n",
        "\n",
        "optimizer = torch.optim.SGD(params=model_1.parameters(),\n",
        "                            lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2 Functionizing training and test loops\n"
      ],
      "metadata": {
        "id": "5jqkEc-Ee35B"
      },
      "id": "5jqkEc-Ee35B"
    },
    {
      "cell_type": "markdown",
      "id": "1eb30af6-a355-49a2-a59f-25169fd27a6e",
      "metadata": {
        "id": "1eb30af6-a355-49a2-a59f-25169fd27a6e"
      },
      "source": [
        "\n",
        "So far we've been writing train and test loops over and over.\n",
        "\n",
        "Let's write them again but this time we'll put them in functions so they can be called again and again.\n",
        "\n",
        "\n",
        "And because we're using device-agnostic code now, we'll be sure to call `.to(device)` on our feature (`X`) and target (`y`) tensors.\n",
        "\n",
        "For the training loop we'll create a function called `train_step()` which takes in a model, a `DataLoader` a loss function and an optimizer.\n",
        "\n",
        "The testing loop will be similar but it'll be called `test_step()` and it'll take in a model, a `DataLoader`, a loss function and an evaluation function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** Since these are functions, you can customize them in any way you like.\n",
        "\n",
        "What we're making here can be considered barebones training and testing functions for our specific classification use case."
      ],
      "metadata": {
        "id": "YDqyHa2Ae5s-"
      },
      "id": "YDqyHa2Ae5s-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "now we don't necessarily need to put this in these type hints in the function\n",
        "\n",
        "but they're relatively new addition to python and so you might start to see them more and more and it also just helps people understand what your code is expecting"
      ],
      "metadata": {
        "id": "FMsGHuSMfx6k"
      },
      "id": "FMsGHuSMfx6k"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "3d239ed2-4028-4603-8db3-ffca2b727819",
      "metadata": {
        "id": "3d239ed2-4028-4603-8db3-ffca2b727819"
      },
      "outputs": [],
      "source": [
        "def train_step(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               accuracy_fn,\n",
        "               device: torch.device = device):\n",
        "\n",
        "    train_loss, train_acc = 0, 0\n",
        "    model.to(device)\n",
        "\n",
        "    for batch, (X, y) in enumerate(data_loader):\n",
        "\n",
        "        # Send data to GPU if available\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 1. Forward pass\n",
        "        y_pred = model(X)\n",
        "\n",
        "        # 2. Calculate loss\n",
        "        loss = loss_fn(y_pred, y)\n",
        "\n",
        "        # accumulate train loss and train accuracy\n",
        "        train_loss += loss\n",
        "        train_acc += accuracy_fn(y_true=y,\n",
        "                                 y_pred=y_pred.argmax(dim=1)) # Go from logits -> pred labels\n",
        "\n",
        "        # 3. Optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Loss backward\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "    # Calculate loss and accuracy per epoch and print out what's happening\n",
        "\n",
        "    train_loss /= len(data_loader)\n",
        "    train_acc /= len(data_loader)\n",
        "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(data_loader: torch.utils.data.DataLoader,\n",
        "              model: torch.nn.Module,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              accuracy_fn,\n",
        "              device: torch.device = device):\n",
        "\n",
        "    test_loss, test_acc = 0, 0\n",
        "    model.to(device)\n",
        "    model.eval() # put model in eval mode\n",
        "\n",
        "    # Turn on inference context manager\n",
        "    with torch.inference_mode():\n",
        "        for X, y in data_loader:\n",
        "            # Send data to GPU\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # 1. Forward pass\n",
        "            test_pred = model(X)\n",
        "\n",
        "            # 2. Calculate loss and accuracy\n",
        "            test_loss += loss_fn(test_pred, y)\n",
        "            test_acc += accuracy_fn(y_true=y,\n",
        "                y_pred=test_pred.argmax(dim=1) # Go from logits -> pred labels\n",
        "            )\n",
        "\n",
        "        # Adjust metrics and print out\n",
        "        test_loss /= len(data_loader)\n",
        "        test_acc /= len(data_loader)\n",
        "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "6-C-0i9ig1ZR"
      },
      "id": "6-C-0i9ig1ZR",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e44121b6-c4be-4909-9175-dc9bd8dc6273",
      "metadata": {
        "id": "e44121b6-c4be-4909-9175-dc9bd8dc6273"
      },
      "source": [
        "Woohoo!\n",
        "\n",
        "Now we've got some functions for training and testing our model,\n",
        "let's run them.\n",
        "\n",
        "This time we are running it on NON_LINEAR Model\n",
        "\n",
        "We'll do so inside another loop for each epoch.\n",
        "\n",
        "That way for each epoch we're going a training and a testing step.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " **Note:** You can customize how often you do a testing step.\\\n",
        " Sometimes people do them every five epochs or 10 epochs or in our case, every epoch.\n",
        "\n",
        "Let's also time things to see how long our code takes to run on the GPU."
      ],
      "metadata": {
        "id": "q2kOT5_4fcrP"
      },
      "id": "q2kOT5_4fcrP"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "2bb8094b-01a0-4b84-9526-ba8888d04901",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327,
          "referenced_widgets": [
            "53f8c4337921437da979586c8eb56e95",
            "5129f06c7cce4356b1ecb4fa67f5f619",
            "9a7d2a0325e541a1acbbd50759e7013d",
            "77ad84a6f6354a489cb43ee5478537d0",
            "0bb71cccac79480d8d9ce27087ebc87f",
            "6d997a523b7043e88f12fb7ec06d7fe5",
            "3f988ee23d354c4bbe386b2c4c269c31",
            "daf6bca7910c48a7abf11e2ff742a554",
            "32fcc20dd34d49548c86049c504c222f",
            "ce69abf81f3647d0943642b27f2cca17",
            "ff990c9cde454e7e828b0e8b085fb682"
          ]
        },
        "id": "2bb8094b-01a0-4b84-9526-ba8888d04901",
        "outputId": "50dfcb07-1a68-4f91-c423-6e8fb1ad99ee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53f8c4337921437da979586c8eb56e95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "---------\n",
            "Train loss: 1.09199 | Train accuracy: 61.34%\n",
            "Test loss: 0.95636 | Test accuracy: 65.00%\n",
            "\n",
            "Epoch: 1\n",
            "---------\n",
            "Train loss: 0.78101 | Train accuracy: 71.93%\n",
            "Test loss: 0.72227 | Test accuracy: 73.91%\n",
            "\n",
            "Epoch: 2\n",
            "---------\n",
            "Train loss: 0.67027 | Train accuracy: 75.94%\n",
            "Test loss: 0.68500 | Test accuracy: 75.02%\n",
            "\n",
            "Train time on cuda: 32.291 seconds\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Measure time\n",
        "from timeit import default_timer as timer\n",
        "train_time_start_on_gpu = timer()  # start timer\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    print(f\"Epoch: {epoch}\\n---------\")\n",
        "    train_step(data_loader=train_dataloader,\n",
        "        model=model_1,\n",
        "        loss_fn=loss_fn,\n",
        "        optimizer=optimizer,\n",
        "        accuracy_fn=accuracy_fn\n",
        "    )\n",
        "\n",
        "    test_step(data_loader=test_dataloader,\n",
        "        model=model_1,\n",
        "        loss_fn=loss_fn,\n",
        "        accuracy_fn=accuracy_fn\n",
        "    )\n",
        "\n",
        "train_time_end_on_gpu = timer() # stop timer()\n",
        "total_train_time_model_1 = print_train_time(start=train_time_start_on_gpu,\n",
        "                                            end=train_time_end_on_gpu,\n",
        "                                            device=device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "it looks like we didn't beat our model 0 results with the non-linear layers and we only just slightly had a faster training time"
      ],
      "metadata": {
        "id": "34aoS1v08UBr"
      },
      "id": "34aoS1v08UBr"
    },
    {
      "cell_type": "markdown",
      "id": "719b8eb9-9a7f-42ed-a49f-5eedc6fdd720",
      "metadata": {
        "id": "719b8eb9-9a7f-42ed-a49f-5eedc6fdd720"
      },
      "source": [
        "Excellent!\n",
        "\n",
        "Our model trained but the training time took longer?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "\n",
        "The training time on CUDA vs CPU will depend largely on the quality of the CPU/GPU you're using. Read on for a more explained answer.\n",
        "\n"
      ],
      "metadata": {
        "id": "GtjWx-mxiAuO"
      },
      "id": "GtjWx-mxiAuO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Question:** \"I used a a GPU but my model didn't train faster, why might that be?\"\n",
        ">\n",
        "> **Answer:** Well, one reason could be because your dataset and model are both so small (like the dataset and model we're working with) the benefits of using a GPU are outweighed by the time it actually takes to transfer the data there.\n",
        ">\n",
        "> There's a small bottleneck between copying data from the CPU memory (default) to the GPU memory.\n",
        ">\n",
        "> So for smaller models and datasets, the CPU might actually be the optimal place to compute on.\n",
        ">\n",
        "> But for larger datasets and models, the speed of computing the GPU can offer usually far outweighs the cost of getting the data there.\n",
        ">\n",
        "> However, this is largely dependant on the hardware you're using. With practice, you will get used to where the best place to train your models is.\n",
        "\n"
      ],
      "metadata": {
        "id": "YCUD5McDiC8q"
      },
      "id": "YCUD5McDiC8q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets get model_1 results dictionary\n",
        "\n",
        "this is helpful so later on we can compare all of our modeling results because they'll all be in dictionary format"
      ],
      "metadata": {
        "id": "OwCYq7za958M"
      },
      "id": "OwCYq7za958M"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's evaluate our trained `model_1` using our `eval_model()` function and see how it went."
      ],
      "metadata": {
        "id": "LQaceYy2iHSa"
      },
      "id": "LQaceYy2iHSa"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "32a544e3-9dbe-4aa1-b074-22e28b8f2f2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "32a544e3-9dbe-4aa1-b074-22e28b8f2f2a",
        "outputId": "30873fe2-6549-42f4-e41b-218a36a1bbc1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-bc4328c0e5b9>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Note: This will error due to `eval_model()` not using device agnostic code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m model_1_results = eval_model(model=model_1,\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdata_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-a1d789f1e62b>\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(model, data_loader, loss_fn, accuracy_fn)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# Make predictions with the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# Accumulate the loss and accuracy values per batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-c1f3784cd5c8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Note: This will error due to `eval_model()` not using device agnostic code\n",
        "model_1_results = eval_model(model=model_1,\n",
        "    data_loader=test_dataloader,\n",
        "    loss_fn=loss_fn,\n",
        "    accuracy_fn=accuracy_fn)\n",
        "\n",
        "model_1_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a3481a5-489d-4db9-ac95-c3ce385978b7",
      "metadata": {
        "id": "6a3481a5-489d-4db9-ac95-c3ce385978b7"
      },
      "source": [
        "Oh no!\n",
        "\n",
        "It looks like our `eval_model()` function errors out with:\n",
        "\n",
        "> `RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's because we've setup our data and model to use device-agnostic code\n",
        "but not in our evaluation function.\n",
        "\n",
        "lets **re-write** `eval_model()` function?\n",
        "\n",
        "How about we fix that by passing a target `device` parameter to our `eval_model()` function?\n",
        "\n",
        "Then we'll try calculating the results again."
      ],
      "metadata": {
        "id": "LNrrTmES-kWE"
      },
      "id": "LNrrTmES-kWE"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "f3665d99-1adc-4d9f-bfc6-e5601a80691c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3665d99-1adc-4d9f-bfc6-e5601a80691c",
        "outputId": "31107366-7823-43ce-9c91-5317c5e948d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_name': 'FashionMNISTModelV1',\n",
              " 'model_loss': 0.6850008964538574,\n",
              " 'model_acc': 75.01996805111821}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# Move values to device\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "def eval_model(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn,\n",
        "               device: torch.device = device):\n",
        "    \"\"\"Evaluates a given model on a given dataset.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.\n",
        "        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.\n",
        "        loss_fn (torch.nn.Module): The loss function of model.\n",
        "        accuracy_fn: An accuracy function to compare the models predictions to the truth labels.\n",
        "        device (str, optional): Target device to compute on. Defaults to device.\n",
        "\n",
        "    Returns:\n",
        "        (dict): Results of model making predictions on data_loader.\n",
        "    \"\"\"\n",
        "    loss, acc = 0, 0\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X, y in data_loader:\n",
        "\n",
        "            # Send data to the target device\n",
        "            X, y = X.to(device), y.to(device)  # This we did not do before\n",
        "            y_pred = model(X)\n",
        "            loss += loss_fn(y_pred, y)\n",
        "            acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
        "\n",
        "        # Scale loss and acc\n",
        "        loss /= len(data_loader)\n",
        "        acc /= len(data_loader)\n",
        "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
        "            \"model_loss\": loss.item(),\n",
        "            \"model_acc\": acc}\n",
        "\n",
        "# Calculate model 1 results with device-agnostic code\n",
        "model_1_results = eval_model(model=model_1, data_loader=test_dataloader,\n",
        "    loss_fn=loss_fn, accuracy_fn=accuracy_fn,\n",
        "    device=device\n",
        ")\n",
        "model_1_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "a9e916cf-f873-4481-a983-bac26ce4cac2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9e916cf-f873-4481-a983-bac26ce4cac2",
        "outputId": "644133ac-911d-4336-cf19-3f2b6e925ecb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_name': 'FashionMNISTModelV0',\n",
              " 'model_loss': 0.47663888335227966,\n",
              " 'model_acc': 83.42651757188499}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "# Check baseline results\n",
        "model_0_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "340cbf14-e83f-4981-8a93-5fedb6b51418",
      "metadata": {
        "id": "340cbf14-e83f-4981-8a93-5fedb6b51418"
      },
      "source": [
        "Woah, in this case, it looks like adding non-linearities to our model made it perform worse than the baseline.\n",
        "\n",
        "That's a thing to note in machine learning, **sometimes** the thing you thought should work **doesn't**.\n",
        "\n",
        "And then the thing you thought might not work does.\n",
        "\n",
        "It's part science, part art.\n",
        "\n",
        "From the looks of things, it seems like our model is **overfitting** on the training data.\n",
        "\n",
        "Overfitting means our model is learning the training data well but those patterns aren't generalizing to the testing data.\n",
        "\n",
        "Two of the main to fix overfitting include:\n",
        "1. Using a smaller or different model (some models fit certain kinds of data better than others).\n",
        "2. Using a larger dataset (the more data, the more chance a model has to learn generalizable patterns).\n",
        "\n",
        "There are more, but I'm going to leave that as a challenge for you to explore.\n",
        "\n",
        "Try searching online, \"ways to prevent overfitting in machine learning\" and see what comes up.\n",
        "\n",
        "In the meantime, let's take a look at number 1: using a different model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Model 2: Building a Convolutional Neural Network (CNN) aka ConvNets\n"
      ],
      "metadata": {
        "id": "ial7iT12APfO"
      },
      "id": "ial7iT12APfO"
    },
    {
      "cell_type": "markdown",
      "id": "ac22d685-1b8d-4215-90de-c0476cb0fbdf",
      "metadata": {
        "id": "ac22d685-1b8d-4215-90de-c0476cb0fbdf"
      },
      "source": [
        "\n",
        "Alright, time to step things up a notch.\n",
        "\n",
        "It's time to create a [Convolutional Neural Network](https://en.wikipedia.org/wiki/Convolutional_neural_network) (CNN or ConvNet).\n",
        "\n",
        "CNN's are known for their capabilities to find patterns in visual data.\n",
        "\n",
        "And since we're dealing with visual data, let's see if using a CNN model can improve upon our baseline.\n",
        "\n",
        "The CNN model we're going to be using is known as TinyVGG from the [CNN Explainer](https://poloclub.github.io/cnn-explainer/) website.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It follows the typical structure of a convolutional neural network:\n",
        "\n",
        "`Input layer -> [Convolutional layer -> activation layer -> pooling layer] -> Output layer`\n",
        "\n",
        "Where the contents of `[Convolutional layer -> activation layer -> pooling layer]` can be upscaled and repeated multiple times, depending on requirements."
      ],
      "metadata": {
        "id": "O8e0dpVTCwPo"
      },
      "id": "O8e0dpVTCwPo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What model should I use?"
      ],
      "metadata": {
        "id": "-9fhcSBQCzEX"
      },
      "id": "-9fhcSBQCzEX"
    },
    {
      "cell_type": "markdown",
      "id": "9c358955-1d20-4903-b872-a239d2753d88",
      "metadata": {
        "id": "9c358955-1d20-4903-b872-a239d2753d88"
      },
      "source": [
        "\n",
        "\n",
        "> **Question:** Wait, you say CNN's are good for images, are there any other model types I should be aware of?\n",
        "\n",
        "Good question.\n",
        "\n",
        "This table is a good general guide for which model to use (though there are exceptions).\n",
        "\n",
        "| **Problem type** | **Model to use (generally)** | **Code example** |\n",
        "| ----- | ----- | ----- |\n",
        "| Structured data (Excel spreadsheets, row and column data) | Gradient boosted models, Random Forests, XGBoost | [`sklearn.ensemble`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble), [XGBoost library](https://xgboost.readthedocs.io/en/stable/) |\n",
        "| Unstructured data (images, audio, language) | Convolutional Neural Networks, Transformers | [`torchvision.models`](https://pytorch.org/vision/stable/models.html), [HuggingFace Transformers](https://huggingface.co/docs/transformers/index) |\n",
        "\n",
        "> **Note:** The table above is only for reference, the model you end up using will be highly dependant on the problem you're working on and the constraints you have (amount of data, latency requirements).\n",
        "\n",
        "Enough talking about models, let's now build a CNN that replicates the model on the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
        "\n",
        "![TinyVGG architecture, as setup by CNN explainer website](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-cnn-explainer-model.png)\n",
        "\n",
        "To do so, we'll leverage the [`nn.Conv2d()`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) and [`nn.MaxPool2d()`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html) layers from `torch.nn`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "so oftentimes when convolutional neural networks or new types of architecture come out\n",
        "\n",
        "the authors of the research paper that present the model get to name the model and so that way in the future you can refer to different types of model architectures with just a simple name like Tinyvgg.\n",
        "\n",
        "\n",
        "that is actually very common practice in machine learning is to find some sort of architecture that someone has found to work on some sort of problem and replicate it with code and see if it works on your own problem"
      ],
      "metadata": {
        "id": "EDKoIb0oD3Qc"
      },
      "id": "EDKoIb0oD3Qc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In convolutional neural networks, \\\n",
        "we have a number of different hyper parameters that we can set \\\n",
        "like kernel_size, stride and padding....\n",
        "\n",
        "you can learn about these hyperparameters on CNN explainer website\n",
        "\n",
        "nn.Conv2d means 2-dimensional\n",
        "\n",
        "\n",
        "In TinyVgg or Cnn,\n",
        "our model is trying to do here is take the input and learn a compressed representation through each of these layers\n",
        "\n",
        "so it's going to smush and smush and smush the input trying to find the most generalizable patterns to get to the ideal outputs.\n",
        "\n",
        "and that input is eventually going to be a feature vector to our final layer"
      ],
      "metadata": {
        "id": "Cdk7lg9nFmwB"
      },
      "id": "Cdk7lg9nFmwB"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "dce60214-63fd-46e2-89ba-125445ac76b7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dce60214-63fd-46e2-89ba-125445ac76b7",
        "outputId": "cd888df5-a86c-4d0b-f966-3d251013f171"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FashionMNISTModelV2(\n",
              "  (block_1): Sequential(\n",
              "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block_2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "# Create a convolutional neural network\n",
        "\n",
        "class FashionMNISTModelV2(nn.Module):\n",
        "    \"\"\"\n",
        "    Model architecture copying TinyVGG from:\n",
        "    https://poloclub.github.io/cnn-explainer/\n",
        "    \"\"\"\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # First block of CNN\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_shape,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3, # how big is the square that's going over the image?\n",
        "                      stride=1, # default\n",
        "                      padding=1),# options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                         stride=2) # default stride value is same as kernel_size\n",
        "        )\n",
        "\n",
        "        # Second block of CNN\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "\n",
        "        # output layer aka classifier layer\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "\n",
        "            # Where did this in_features shape come from?\n",
        "            # It's because each layer of our network compresses and changes the shape of our inputs data.\n",
        "\n",
        "            nn.Linear(in_features=hidden_units*7*7, # sometimes calculating what you're in_features needs to be is quite tricky\n",
        "                      out_features=output_shape) # length of classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.block_1(x)\n",
        "        #print(f\"Output shape of conv_block_1: {x.shape}\")\n",
        "        x = self.block_2(x)\n",
        "        #print(f\"Output shape of conv_block_2: {x.shape}\")\n",
        "        x = self.classifier(x)\n",
        "        #print(f\"Output shape of classifier layer: {x.shape}\")\n",
        "        return x\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "model_2 = FashionMNISTModelV2(input_shape=1, # remeber this input goes to Conv2d and it is no. of color channels in our image\n",
        "                              hidden_units=10, # same as TinyVGG\n",
        "                              output_shape=len(class_names)).to(device)\n",
        "model_2\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a20f25e-cc16-4f85-a69b-62008c01d0ed",
      "metadata": {
        "id": "0a20f25e-cc16-4f85-a69b-62008c01d0ed"
      },
      "source": [
        "Nice!\n",
        "\n",
        "Our biggest model yet!\n",
        "\n",
        "What we've done is a common practice in machine learning.\n",
        "\n",
        "Find a model architecture somewhere and replicate it with code."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to decide on shape of in_features in classifier layer ?\n",
        "\n"
      ],
      "metadata": {
        "id": "zaba55GjfZGc"
      },
      "id": "zaba55GjfZGc"
    },
    {
      "cell_type": "markdown",
      "source": [
        " first, we can use the formula that is described in Pytorch website nn.Conv2d\n",
        "\n",
        "\n",
        " Second is easy, \\\n",
        "After passing the image aka tensor thru the second block of conv in the forward pass, we can print the shape of our tensor\n",
        "\n",
        "for example,  \\\n",
        "if shape is (1,10,7,7) and since we are passing to flatten layer\n",
        "before actual classification\n",
        "\n",
        "we can use 10 * 7 * 7\n",
        "\n"
      ],
      "metadata": {
        "id": "kRV1CL5Mfg03"
      },
      "id": "kRV1CL5Mfg03"
    },
    {
      "cell_type": "markdown",
      "source": [
        "now we introduced two new layers that we haven't seen before Conv2d and\n",
        "MaxPool2d\n",
        "\n",
        "but they all have the same sort of premise of what we've been doing so far is that they're trying to learn the best features to represent our data in some way shape or form\n",
        "\n",
        "now in the case of MaxPool2d it doesn't actually have any learnable parameters\n",
        "\n",
        "but lets first look at conv2d()\n"
      ],
      "metadata": {
        "id": "WaD0hXTEKv9B"
      },
      "id": "WaD0hXTEKv9B"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1 Stepping through `nn.Conv2d()`\n"
      ],
      "metadata": {
        "id": "meOLmjh3Ics3"
      },
      "id": "meOLmjh3Ics3"
    },
    {
      "cell_type": "markdown",
      "id": "6478cc5a-7b33-425d-9ab3-6d40168a1aee",
      "metadata": {
        "id": "6478cc5a-7b33-425d-9ab3-6d40168a1aee"
      },
      "source": [
        "\n",
        "We could start using our model above and see what happens but let's first step through the two new layers we've added:\n",
        "* [`nn.Conv2d()`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html), also known as a convolutional layer.\n",
        "* [`nn.MaxPool2d()`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html), also known as a max pooling layer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Question:** What does the \"2d\" in `nn.Conv2d()` stand for?\n",
        ">\n",
        "> The 2d is for 2-dimensional data. As in, our images have two dimensions: height and width. Yes, there's color channel dimension but each of the color channel dimensions have two dimensions too: height and width.\n",
        ">\n",
        "> For other dimensional data (such as 1D for text or 3D for 3D objects) there's also `nn.Conv1d()` and `nn.Conv3d()`.\n",
        "\n",
        "To test the layers out, let's create some toy data just like the data used on CNN Explainer."
      ],
      "metadata": {
        "id": "vxZ94Ci6JRS0"
      },
      "id": "vxZ94Ci6JRS0"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "058b01ac-3f6a-4472-bcbf-3377974e3254",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "058b01ac-3f6a-4472-bcbf-3377974e3254",
        "outputId": "4dc6c1c9-5975-41cc-f040-3483ac0aab3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image batch shape: torch.Size([32, 3, 64, 64]) -> [batch_size, color_channels, height, width]\n",
            "Single image shape: torch.Size([3, 64, 64]) -> [color_channels, height, width]\n",
            "\n",
            "Single image pixel values:\n",
            "tensor([[[ 1.9269,  1.4873,  0.9007,  ...,  1.8446, -1.1845,  1.3835],\n",
            "         [ 1.4451,  0.8564,  2.2181,  ...,  0.3399,  0.7200,  0.4114],\n",
            "         [ 1.9312,  1.0119, -1.4364,  ..., -0.5558,  0.7043,  0.7099],\n",
            "         ...,\n",
            "         [-0.5610, -0.4830,  0.4770,  ..., -0.2713, -0.9537, -0.6737],\n",
            "         [ 0.3076, -0.1277,  0.0366,  ..., -2.0060,  0.2824, -0.8111],\n",
            "         [-1.5486,  0.0485, -0.7712,  ..., -0.1403,  0.9416, -0.0118]],\n",
            "\n",
            "        [[-0.5197,  1.8524,  1.8365,  ...,  0.8935, -1.5114, -0.8515],\n",
            "         [ 2.0818,  1.0677, -1.4277,  ...,  1.6612, -2.6223, -0.4319],\n",
            "         [-0.1010, -0.4388, -1.9775,  ...,  0.2106,  0.2536, -0.7318],\n",
            "         ...,\n",
            "         [ 0.2779,  0.7342, -0.3736,  ..., -0.4601,  0.1815,  0.1850],\n",
            "         [ 0.7205, -0.2833,  0.0937,  ..., -0.1002, -2.3609,  2.2465],\n",
            "         [-1.3242, -0.1973,  0.2920,  ...,  0.5409,  0.6940,  1.8563]],\n",
            "\n",
            "        [[-0.7978,  1.0261,  1.1465,  ...,  1.2134,  0.9354, -0.0780],\n",
            "         [-1.4647, -1.9571,  0.1017,  ..., -1.9986, -0.7409,  0.7011],\n",
            "         [-1.3938,  0.8466, -1.7191,  ..., -1.1867,  0.1320,  0.3407],\n",
            "         ...,\n",
            "         [ 0.8206, -0.3745,  1.2499,  ..., -0.0676,  0.0385,  0.6335],\n",
            "         [-0.5589, -0.3393,  0.2347,  ...,  2.1181,  2.4569,  1.3083],\n",
            "         [-0.4092,  1.5199,  0.2401,  ..., -0.2558,  0.7870,  0.9924]]])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Create sample batch of random numbers with same size as image batch\n",
        "\n",
        "images = torch.randn(size=(32, 3, 64, 64)) # [batch_size, color_channels, height, width] # NCHW - color channels first\n",
        "test_image = images[0] # get a single image for testing\n",
        "\n",
        "print(f\"Image batch shape: {images.shape} -> [batch_size, color_channels, height, width]\")\n",
        "print(f\"Single image shape: {test_image.shape} -> [color_channels, height, width]\", end = '\\n\\n')\n",
        "print(f\"Single image pixel values:\\n{test_image}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd3291c2-854e-4d0c-97b9-8bf46085fc43",
      "metadata": {
        "id": "bd3291c2-854e-4d0c-97b9-8bf46085fc43"
      },
      "source": [
        "Let's create an example `nn.Conv2d()` with various parameters:\n",
        "* `in_channels` (int) - Number of channels in the input image.\n",
        "* `out_channels` (int) - Number of channels produced by the convolution.\n",
        "* `kernel_size` (int or tuple) - Size of the convolving kernel/filter.\n",
        "* `stride` (int or tuple, optional) - How big of a step the convolving kernel takes at a time. Default: 1.\n",
        "* `padding` (int, tuple, str) - Padding added to all four sides of input. Default: 0.\n",
        "\n",
        "![example of going through the different parameters of a Conv2d layer](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-conv2d-layer.gif)\n",
        "\n",
        "*Example of what happens when you change the hyperparameters of a `nn.Conv2d()` layer.*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "so let's see what happens \\  \n",
        "if we pass some random data through one of our Conv2d() layers"
      ],
      "metadata": {
        "id": "B5L3PalFL0Zv"
      },
      "id": "B5L3PalFL0Zv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "how do we know what hyperparameters to set them\n",
        "\n",
        "so It's often very common in machine learning is that when you're just getting started and you're not sure what values to set these values to you just copy some existing values from somewhere and see if it works on your own problem\n",
        "\n",
        "In our case, we are using TinyVGG"
      ],
      "metadata": {
        "id": "NhPj9_1gNDY8"
      },
      "id": "NhPj9_1gNDY8"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "ebd39562-1dad-40e3-90f5-750a5dac24e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebd39562-1dad-40e3-90f5-750a5dac24e2",
        "outputId": "17143644-1160-439b-e228-33cbff77baec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.5396,  0.0516,  0.6454,  ..., -0.3673,  0.8711,  0.4256],\n",
              "         [ 0.3662,  1.0114, -0.5997,  ...,  0.8983,  0.2809, -0.2741],\n",
              "         [ 1.2664, -1.4054,  0.3727,  ..., -0.3409,  1.2191, -0.0463],\n",
              "         ...,\n",
              "         [-0.1541,  0.5132, -0.3624,  ..., -0.2360, -0.4609, -0.0035],\n",
              "         [ 0.2981, -0.2432,  1.5012,  ..., -0.6289, -0.7283, -0.5767],\n",
              "         [-0.0386, -0.0781, -0.0388,  ...,  0.2842,  0.4228, -0.1802]],\n",
              "\n",
              "        [[-0.2840, -0.0319, -0.4455,  ..., -0.7956,  1.5599, -1.2449],\n",
              "         [ 0.2753, -0.1262, -0.6541,  ..., -0.2211,  0.1999, -0.8856],\n",
              "         [-0.5404, -1.5489,  0.0249,  ..., -0.5932, -1.0913, -0.3849],\n",
              "         ...,\n",
              "         [ 0.3870, -0.4064, -0.8236,  ...,  0.1734, -0.4330, -0.4951],\n",
              "         [-0.1984, -0.6386,  1.0263,  ..., -0.9401, -0.0585, -0.7833],\n",
              "         [-0.6306, -0.2052, -0.3694,  ..., -1.3248,  0.2456, -0.7134]],\n",
              "\n",
              "        [[ 0.4414,  0.5100,  0.4846,  ..., -0.8484,  0.2638,  1.1258],\n",
              "         [ 0.8117,  0.3191, -0.0157,  ...,  1.2686,  0.2319,  0.5003],\n",
              "         [ 0.3212,  0.0485, -0.2581,  ...,  0.2258,  0.2587, -0.8804],\n",
              "         ...,\n",
              "         [-0.1144, -0.1869,  0.0160,  ..., -0.8346,  0.0974,  0.8421],\n",
              "         [ 0.2941,  0.4417,  0.5866,  ..., -0.1224,  0.4814, -0.4799],\n",
              "         [ 0.6059, -0.0415, -0.2028,  ...,  0.1170,  0.2521, -0.4372]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-0.2560, -0.0477,  0.6380,  ...,  0.6436,  0.7553, -0.7055],\n",
              "         [ 1.5595, -0.2209, -0.9486,  ..., -0.4876,  0.7754,  0.0750],\n",
              "         [-0.0797,  0.2471,  1.1300,  ...,  0.1505,  0.2354,  0.9576],\n",
              "         ...,\n",
              "         [ 1.1065,  0.6839,  1.2183,  ...,  0.3015, -0.1910, -0.1902],\n",
              "         [-0.3486, -0.7173, -0.3582,  ...,  0.4917,  0.7219,  0.1513],\n",
              "         [ 0.0119,  0.1017,  0.7839,  ..., -0.3752, -0.8127, -0.1257]],\n",
              "\n",
              "        [[ 0.3841,  1.1322,  0.1620,  ...,  0.7010,  0.0109,  0.6058],\n",
              "         [ 0.1664,  0.1873,  1.5924,  ...,  0.3733,  0.9096, -0.5399],\n",
              "         [ 0.4094, -0.0861, -0.7935,  ..., -0.1285, -0.9932, -0.3013],\n",
              "         ...,\n",
              "         [ 0.2688, -0.5630, -1.1902,  ...,  0.4493,  0.5404, -0.0103],\n",
              "         [ 0.0535,  0.4411,  0.5313,  ...,  0.0148, -1.0056,  0.3759],\n",
              "         [ 0.3031, -0.1590, -0.1316,  ..., -0.5384, -0.4271, -0.4876]],\n",
              "\n",
              "        [[-1.1865, -0.7280, -1.2331,  ..., -0.9013, -0.0542, -1.5949],\n",
              "         [-0.6345, -0.5920,  0.5326,  ..., -1.0395, -0.7963, -0.0647],\n",
              "         [-0.1132,  0.5166,  0.2569,  ...,  0.5595, -1.6881,  0.9485],\n",
              "         ...,\n",
              "         [-0.0254, -0.2669,  0.1927,  ..., -0.2917,  0.1088, -0.4807],\n",
              "         [-0.2609, -0.2328,  0.1404,  ..., -0.1325, -0.8436, -0.7524],\n",
              "         [-1.1399, -0.1751, -0.8705,  ...,  0.1589,  0.3377,  0.3493]]],\n",
              "       grad_fn=<SqueezeBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Create a convolutional layer with same dimensions as TinyVGG\n",
        "# (try changing any of the parameters and see what happens)\n",
        "\n",
        "conv_layer = nn.Conv2d(in_channels=3,  # color channel\n",
        "                       out_channels=10, # Hidden units\n",
        "                       kernel_size=3, # aka Filter and 3 = (3,3)\n",
        "                       stride=1, # slide kernel 1 pixel at a time\n",
        "                       padding=0) # add extra pixels around the image for the kernel to consider --- also try using \"valid\" or \"same\" here\n",
        "\n",
        "# Pass the data through the convolutional layer\n",
        "\n",
        "conv_layer(test_image)\n",
        "\n",
        "# Note: If running PyTorch <1.11.0, this will error because of shape issues (nn.Conv.2d() expects a 4d tensor as input)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb0184ad-5c16-4e1c-bcfa-70ecf15377da",
      "metadata": {
        "id": "cb0184ad-5c16-4e1c-bcfa-70ecf15377da"
      },
      "source": [
        "If we try to pass a single image in, we get a shape mismatch error:\n",
        "\n",
        "> `RuntimeError: Expected 4-dimensional input for 4-dimensional weight [10, 3, 3, 3], but got 3-dimensional input of size [3, 64, 64] instead`\n",
        ">\n",
        "> **Note:** If you're running PyTorch 1.11.0+, this error won't occur.\n",
        "\n",
        "This is because our `nn.Conv2d()` layer expects a 4-dimensional tensor as input with size `(N, C, H, W)` or `[batch_size, color_channels, height, width]`.\n",
        "\n",
        "Right now our single image `test_image` only has a shape of `[color_channels, height, width]` or `[3, 64, 64]`.\n",
        "\n",
        "We can fix this for a single image using `test_image.unsqueeze(dim=0)` to add an extra dimension for `N`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_image.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy6kxq0OOkbf",
        "outputId": "458d82a3-0d86-45dd-fae2-24bdc85a71d0"
      },
      "id": "Uy6kxq0OOkbf",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "abba741d-a1ed-44ed-ba53-41d589433a2c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abba741d-a1ed-44ed-ba53-41d589433a2c",
        "outputId": "6bf36cdf-b092-43b5-9ac9-b91a4126ec83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "# Add extra dimension to test image\n",
        "\n",
        "test_image.unsqueeze(dim=0).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "c7280a49-4ee0-452b-a514-61115b6a444c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7280a49-4ee0-452b-a514-61115b6a444c",
        "outputId": "2a009daa-eab5-4c53-fe6b-20a83f7d0aa6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 62, 62])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "\n",
        "# Pass test image with extra dimension through conv_layer\n",
        "\n",
        "conv_layer(test_image.unsqueeze(dim=0)).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "181df81b-7c5a-46cc-b8d5-a592bf755a13",
      "metadata": {
        "id": "181df81b-7c5a-46cc-b8d5-a592bf755a13"
      },
      "source": [
        "Hmm, notice what happens to our shape (the same shape as the first layer of TinyVGG on [CNN Explainer](https://poloclub.github.io/cnn-explainer/)),\n",
        "\n",
        "we get different channel sizes as well as different pixel sizes.\n",
        "\n",
        "What if we changed the values of `conv_layer`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "04445d45-cf2f-4c1d-b215-bc50865a207a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04445d45-cf2f-4c1d-b215-bc50865a207a",
        "outputId": "ca5a10cd-a481-4b35-d63c-730f4271b3b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 30, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Create a new conv_layer with different values (try setting these to whatever you like)\n",
        "conv_layer_2 = nn.Conv2d(in_channels=3, # same number of color channels as our input image\n",
        "                         out_channels=10,\n",
        "                         kernel_size=(5, 5), # kernel is usually a square so a tuple also works\n",
        "                         stride=2,\n",
        "                         padding=0)\n",
        "\n",
        "# Pass single image through new conv_layer_2 (this calls nn.Conv2d()'s forward() method on the input)\n",
        "\n",
        "conv_layer_2(test_image.unsqueeze(dim=0)).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b27dbdbb-3e32-4ffa-803e-cf943d96c72b",
      "metadata": {
        "id": "b27dbdbb-3e32-4ffa-803e-cf943d96c72b"
      },
      "source": [
        "Woah, we get another shape change.\n",
        "\n",
        "Now our image is of shape `[1, 10, 30, 30]`\n",
        " or `[batch_size=1, color_channels=10, height=30, width=30]`.\n",
        "\n",
        "Shapes will be different if you use different values for kernel, stride\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What's going on here?\n",
        "\n",
        "Behind the scenes, our `nn.Conv2d()` is compressing the information stored in the image.\n",
        "\n",
        "It does this by performing operations on the input (our test image) against its internal parameters.\n",
        "\n",
        "The goal of this is similar to all of the other neural networks we've been building.\n",
        "\n",
        "Data goes in and the layers try to update their internal parameters (patterns) to lower the loss function thanks to some help of the optimizer.\n",
        "\n",
        "The only difference is *how* the different layers calculate their parameter updates or in PyTorch terms, the operation present in the layer `forward()` method.\n",
        "\n",
        "If we check out our `conv_layer_2.state_dict()` we'll find a similar weight and bias setup as we've seen before."
      ],
      "metadata": {
        "id": "yhJBuIeRZmz0"
      },
      "id": "yhJBuIeRZmz0"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "46027ed1-c3a7-46bd-bab7-17f8c20e354b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46027ed1-c3a7-46bd-bab7-17f8c20e354b",
        "outputId": "4d21c717-b11c-4ea6-f95c-5fe74f632fd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('weight', tensor([[[[ 0.0883,  0.0958, -0.0271,  0.1061, -0.0253],\n",
            "          [ 0.0233, -0.0562,  0.0678,  0.1018, -0.0847],\n",
            "          [ 0.1004,  0.0216,  0.0853,  0.0156,  0.0557],\n",
            "          [-0.0163,  0.0890,  0.0171, -0.0539,  0.0294],\n",
            "          [-0.0532, -0.0135, -0.0469,  0.0766, -0.0911]],\n",
            "\n",
            "         [[-0.0532, -0.0326, -0.0694,  0.0109, -0.1140],\n",
            "          [ 0.1043, -0.0981,  0.0891,  0.0192, -0.0375],\n",
            "          [ 0.0714,  0.0180,  0.0933,  0.0126, -0.0364],\n",
            "          [ 0.0310, -0.0313,  0.0486,  0.1031,  0.0667],\n",
            "          [-0.0505,  0.0667,  0.0207,  0.0586, -0.0704]],\n",
            "\n",
            "         [[-0.1143, -0.0446, -0.0886,  0.0947,  0.0333],\n",
            "          [ 0.0478,  0.0365, -0.0020,  0.0904, -0.0820],\n",
            "          [ 0.0073, -0.0788,  0.0356, -0.0398,  0.0354],\n",
            "          [-0.0241,  0.0958, -0.0684, -0.0689, -0.0689],\n",
            "          [ 0.1039,  0.0385,  0.1111, -0.0953, -0.1145]]],\n",
            "\n",
            "\n",
            "        [[[-0.0903, -0.0777,  0.0468,  0.0413,  0.0959],\n",
            "          [-0.0596, -0.0787,  0.0613, -0.0467,  0.0701],\n",
            "          [-0.0274,  0.0661, -0.0897, -0.0583,  0.0352],\n",
            "          [ 0.0244, -0.0294,  0.0688,  0.0785, -0.0837],\n",
            "          [-0.0616,  0.1057, -0.0390, -0.0409, -0.1117]],\n",
            "\n",
            "         [[-0.0661,  0.0288, -0.0152, -0.0838,  0.0027],\n",
            "          [-0.0789, -0.0980, -0.0636, -0.1011, -0.0735],\n",
            "          [ 0.1154,  0.0218,  0.0356, -0.1077, -0.0758],\n",
            "          [-0.0384,  0.0181, -0.1016, -0.0498, -0.0691],\n",
            "          [ 0.0003, -0.0430, -0.0080, -0.0782, -0.0793]],\n",
            "\n",
            "         [[-0.0674, -0.0395, -0.0911,  0.0968, -0.0229],\n",
            "          [ 0.0994,  0.0360, -0.0978,  0.0799, -0.0318],\n",
            "          [-0.0443, -0.0958, -0.1148,  0.0330, -0.0252],\n",
            "          [ 0.0450, -0.0948,  0.0857, -0.0848, -0.0199],\n",
            "          [ 0.0241,  0.0596,  0.0932,  0.1052, -0.0916]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0291, -0.0497, -0.0127, -0.0864,  0.1052],\n",
            "          [-0.0847,  0.0617,  0.0406,  0.0375, -0.0624],\n",
            "          [ 0.1050,  0.0254,  0.0149, -0.1018,  0.0485],\n",
            "          [-0.0173, -0.0529,  0.0992,  0.0257, -0.0639],\n",
            "          [-0.0584, -0.0055,  0.0645, -0.0295, -0.0659]],\n",
            "\n",
            "         [[-0.0395, -0.0863,  0.0412,  0.0894, -0.1087],\n",
            "          [ 0.0268,  0.0597,  0.0209, -0.0411,  0.0603],\n",
            "          [ 0.0607,  0.0432, -0.0203, -0.0306,  0.0124],\n",
            "          [-0.0204, -0.0344,  0.0738,  0.0992, -0.0114],\n",
            "          [-0.0259,  0.0017, -0.0069,  0.0278,  0.0324]],\n",
            "\n",
            "         [[-0.1049, -0.0426,  0.0972,  0.0450, -0.0057],\n",
            "          [-0.0696, -0.0706, -0.1034, -0.0376,  0.0390],\n",
            "          [ 0.0736,  0.0533, -0.1021, -0.0694, -0.0182],\n",
            "          [ 0.1117,  0.0167, -0.0299,  0.0478, -0.0440],\n",
            "          [-0.0747,  0.0843, -0.0525, -0.0231, -0.1149]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0773,  0.0875,  0.0421, -0.0805, -0.1140],\n",
            "          [-0.0938,  0.0861,  0.0554,  0.0972,  0.0605],\n",
            "          [ 0.0292, -0.0011, -0.0878, -0.0989, -0.1080],\n",
            "          [ 0.0473, -0.0567, -0.0232, -0.0665, -0.0210],\n",
            "          [-0.0813, -0.0754,  0.0383, -0.0343,  0.0713]],\n",
            "\n",
            "         [[-0.0370, -0.0847, -0.0204, -0.0560, -0.0353],\n",
            "          [-0.1099,  0.0646, -0.0804,  0.0580,  0.0524],\n",
            "          [ 0.0825, -0.0886,  0.0830, -0.0546,  0.0428],\n",
            "          [ 0.1084, -0.0163, -0.0009, -0.0266, -0.0964],\n",
            "          [ 0.0554, -0.1146,  0.0717,  0.0864,  0.1092]],\n",
            "\n",
            "         [[-0.0272, -0.0949,  0.0260,  0.0638, -0.1149],\n",
            "          [-0.0262, -0.0692, -0.0101, -0.0568, -0.0472],\n",
            "          [-0.0367, -0.1097,  0.0947,  0.0968, -0.0181],\n",
            "          [-0.0131, -0.0471, -0.1043, -0.1124,  0.0429],\n",
            "          [-0.0634, -0.0742, -0.0090, -0.0385, -0.0374]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0037, -0.0245, -0.0398, -0.0553, -0.0940],\n",
            "          [ 0.0968, -0.0462,  0.0306, -0.0401,  0.0094],\n",
            "          [ 0.1077,  0.0532, -0.1001,  0.0458,  0.1096],\n",
            "          [ 0.0304,  0.0774,  0.1138, -0.0177,  0.0240],\n",
            "          [-0.0803, -0.0238,  0.0855,  0.0592, -0.0731]],\n",
            "\n",
            "         [[-0.0926, -0.0789, -0.1140, -0.0891, -0.0286],\n",
            "          [ 0.0779,  0.0193, -0.0878, -0.0926,  0.0574],\n",
            "          [-0.0859, -0.0142,  0.0554, -0.0534, -0.0126],\n",
            "          [-0.0101, -0.0273, -0.0585, -0.1029, -0.0933],\n",
            "          [-0.0618,  0.1115, -0.0558, -0.0775,  0.0280]],\n",
            "\n",
            "         [[ 0.0318,  0.0633,  0.0878,  0.0643, -0.1145],\n",
            "          [ 0.0102,  0.0699, -0.0107, -0.0680,  0.1101],\n",
            "          [-0.0432, -0.0657, -0.1041,  0.0052,  0.0512],\n",
            "          [ 0.0256,  0.0228, -0.0876, -0.1078,  0.0020],\n",
            "          [ 0.1053,  0.0666, -0.0672, -0.0150, -0.0851]]],\n",
            "\n",
            "\n",
            "        [[[-0.0557,  0.0209,  0.0629,  0.0957, -0.1060],\n",
            "          [ 0.0772, -0.0814,  0.0432,  0.0977,  0.0016],\n",
            "          [ 0.1051, -0.0984, -0.0441,  0.0673, -0.0252],\n",
            "          [-0.0236, -0.0481,  0.0796,  0.0566,  0.0370],\n",
            "          [-0.0649, -0.0937,  0.0125,  0.0342, -0.0533]],\n",
            "\n",
            "         [[-0.0323,  0.0780,  0.0092,  0.0052, -0.0284],\n",
            "          [-0.1046, -0.1086, -0.0552, -0.0587,  0.0360],\n",
            "          [-0.0336, -0.0452,  0.1101,  0.0402,  0.0823],\n",
            "          [-0.0559, -0.0472,  0.0424, -0.0769, -0.0755],\n",
            "          [-0.0056, -0.0422, -0.0866,  0.0685,  0.0929]],\n",
            "\n",
            "         [[ 0.0187, -0.0201, -0.1070, -0.0421,  0.0294],\n",
            "          [ 0.0544, -0.0146, -0.0457,  0.0643, -0.0920],\n",
            "          [ 0.0730, -0.0448,  0.0018, -0.0228,  0.0140],\n",
            "          [-0.0349,  0.0840, -0.0030,  0.0901,  0.1110],\n",
            "          [-0.0563, -0.0842,  0.0926,  0.0905, -0.0882]]],\n",
            "\n",
            "\n",
            "        [[[-0.0089, -0.1139, -0.0945,  0.0223,  0.0307],\n",
            "          [ 0.0245, -0.0314,  0.1065,  0.0165, -0.0681],\n",
            "          [-0.0065,  0.0277,  0.0404, -0.0816,  0.0433],\n",
            "          [-0.0590, -0.0959, -0.0631,  0.1114,  0.0987],\n",
            "          [ 0.1034,  0.0678,  0.0872, -0.0155, -0.0635]],\n",
            "\n",
            "         [[ 0.0577, -0.0598, -0.0779, -0.0369,  0.0242],\n",
            "          [ 0.0594, -0.0448, -0.0680,  0.0156, -0.0681],\n",
            "          [-0.0752,  0.0602, -0.0194,  0.1055,  0.1123],\n",
            "          [ 0.0345,  0.0397,  0.0266,  0.0018, -0.0084],\n",
            "          [ 0.0016,  0.0431,  0.1074, -0.0299, -0.0488]],\n",
            "\n",
            "         [[-0.0280, -0.0558,  0.0196,  0.0862,  0.0903],\n",
            "          [ 0.0530, -0.0850, -0.0620, -0.0254, -0.0213],\n",
            "          [ 0.0095, -0.1060,  0.0359, -0.0881, -0.0731],\n",
            "          [-0.0960,  0.1006, -0.1093,  0.0871, -0.0039],\n",
            "          [-0.0134,  0.0722, -0.0107,  0.0724,  0.0835]]],\n",
            "\n",
            "\n",
            "        [[[-0.1003,  0.0444,  0.0218,  0.0248,  0.0169],\n",
            "          [ 0.0316, -0.0555, -0.0148,  0.1097,  0.0776],\n",
            "          [-0.0043, -0.1086,  0.0051, -0.0786,  0.0939],\n",
            "          [-0.0701, -0.0083, -0.0256,  0.0205,  0.1087],\n",
            "          [ 0.0110,  0.0669,  0.0896,  0.0932, -0.0399]],\n",
            "\n",
            "         [[-0.0258,  0.0556, -0.0315,  0.0541, -0.0252],\n",
            "          [-0.0783,  0.0470,  0.0177,  0.0515,  0.1147],\n",
            "          [ 0.0788,  0.1095,  0.0062, -0.0993, -0.0810],\n",
            "          [-0.0717, -0.1018, -0.0579, -0.1063, -0.1065],\n",
            "          [-0.0690, -0.1138, -0.0709,  0.0440,  0.0963]],\n",
            "\n",
            "         [[-0.0343, -0.0336,  0.0617, -0.0570, -0.0546],\n",
            "          [ 0.0711, -0.1006,  0.0141,  0.1020,  0.0198],\n",
            "          [ 0.0314, -0.0672, -0.0016,  0.0063,  0.0283],\n",
            "          [ 0.0449,  0.1003, -0.0881,  0.0035, -0.0577],\n",
            "          [-0.0913, -0.0092, -0.1016,  0.0806,  0.0134]]],\n",
            "\n",
            "\n",
            "        [[[-0.0622,  0.0603, -0.1093, -0.0447, -0.0225],\n",
            "          [-0.0981, -0.0734, -0.0188,  0.0876,  0.1115],\n",
            "          [ 0.0735, -0.0689, -0.0755,  0.1008,  0.0408],\n",
            "          [ 0.0031,  0.0156, -0.0928, -0.0386,  0.1112],\n",
            "          [-0.0285, -0.0058, -0.0959, -0.0646, -0.0024]],\n",
            "\n",
            "         [[-0.0717, -0.0143,  0.0470, -0.1130,  0.0343],\n",
            "          [-0.0763, -0.0564,  0.0443,  0.0918, -0.0316],\n",
            "          [-0.0474, -0.1044, -0.0595, -0.1011, -0.0264],\n",
            "          [ 0.0236, -0.1082,  0.1008,  0.0724, -0.1130],\n",
            "          [-0.0552,  0.0377, -0.0237, -0.0126, -0.0521]],\n",
            "\n",
            "         [[ 0.0927, -0.0645,  0.0958,  0.0075,  0.0232],\n",
            "          [ 0.0901, -0.0190, -0.0657, -0.0187,  0.0937],\n",
            "          [-0.0857,  0.0262, -0.1135,  0.0605,  0.0427],\n",
            "          [ 0.0049,  0.0496,  0.0001,  0.0639, -0.0914],\n",
            "          [-0.0170,  0.0512,  0.1150,  0.0588, -0.0840]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0888, -0.0257, -0.0247, -0.1050, -0.0182],\n",
            "          [ 0.0817,  0.0161, -0.0673,  0.0355, -0.0370],\n",
            "          [ 0.1054, -0.1002, -0.0365, -0.1115, -0.0455],\n",
            "          [ 0.0364,  0.1112,  0.0194,  0.1132,  0.0226],\n",
            "          [ 0.0667,  0.0926,  0.0965, -0.0646,  0.1062]],\n",
            "\n",
            "         [[ 0.0699, -0.0540, -0.0551, -0.0969,  0.0290],\n",
            "          [-0.0936,  0.0488,  0.0365, -0.1003,  0.0315],\n",
            "          [-0.0094,  0.0527,  0.0663, -0.1148,  0.1059],\n",
            "          [ 0.0968,  0.0459, -0.1055, -0.0412, -0.0335],\n",
            "          [-0.0297,  0.0651,  0.0420,  0.0915, -0.0432]],\n",
            "\n",
            "         [[ 0.0389,  0.0411, -0.0961, -0.1120, -0.0599],\n",
            "          [ 0.0790, -0.1087, -0.1005,  0.0647,  0.0623],\n",
            "          [ 0.0950, -0.0872, -0.0845,  0.0592,  0.1004],\n",
            "          [ 0.0691,  0.0181,  0.0381,  0.1096, -0.0745],\n",
            "          [-0.0524,  0.0808, -0.0790, -0.0637,  0.0843]]]])), ('bias', tensor([ 0.0364,  0.0373, -0.0489, -0.0016,  0.1057, -0.0693,  0.0009,  0.0549,\n",
            "        -0.0797,  0.1121]))])\n"
          ]
        }
      ],
      "source": [
        "# Check out the conv_layer_2 internal parameters\n",
        "\n",
        "print(conv_layer_2.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b708eb6-ae46-4d8c-a8a4-1392827d3e37",
      "metadata": {
        "id": "8b708eb6-ae46-4d8c-a8a4-1392827d3e37"
      },
      "source": [
        "Look at that! A bunch of random numbers for a weight and bias tensor.\n",
        "\n",
        "The shapes of these are manipulated by the inputs we passed to `nn.Conv2d()` when we set it up.\n",
        "\n",
        "Let's check them out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "e5518d61-c0b7-4351-b5ea-4d6b6144291a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5518d61-c0b7-4351-b5ea-4d6b6144291a",
        "outputId": "7c403084-4ac4-43d2-8c4a-712bdc3b9def"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv_layer_2 weight shape: \n",
            "torch.Size([10, 3, 5, 5]) -> [out_channels=10, in_channels=3, kernel_size=5, kernel_size=5]\n",
            "\n",
            "conv_layer_2 bias shape: \n",
            "torch.Size([10]) -> [out_channels=10]\n"
          ]
        }
      ],
      "source": [
        "# Get shapes of weight and bias tensors within conv_layer_2\n",
        "\n",
        "print(f\"conv_layer_2 weight shape: \\n{conv_layer_2.weight.shape} -> [out_channels=10, in_channels=3, kernel_size=5, kernel_size=5]\")\n",
        "\n",
        "print(f\"\\nconv_layer_2 bias shape: \\n{conv_layer_2.bias.shape} -> [out_channels=10]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0de23c7-4501-4156-80a4-ac889a636a42",
      "metadata": {
        "id": "f0de23c7-4501-4156-80a4-ac889a636a42"
      },
      "source": [
        "> **Question:** What should we set the parameters of our `nn.Conv2d()` layers?\n",
        ">\n",
        "> That's a good one. But similar to many other things in machine learning, the values of these aren't set in stone (and recall, because these values are ones we can set ourselves, they're referred to as \"**hyperparameters**\").\n",
        ">\n",
        "> The best way to find out is to try out different values and see how they effect your model's performance.\n",
        ">\n",
        "> Or even better, find a working example on a problem similar to yours (like we've done with TinyVGG) and copy it.\n",
        "\n",
        "We're working with a different of layer here to what we've seen before.\n",
        "\n",
        "But the premise remains the same: start with random numbers and update them to better represent the data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2 Stepping through `nn.MaxPool2d()`"
      ],
      "metadata": {
        "id": "QZPEh1vUYfHx"
      },
      "id": "QZPEh1vUYfHx"
    },
    {
      "cell_type": "markdown",
      "id": "6370d45d-ca44-4fa0-a2d7-efaf0a207b91",
      "metadata": {
        "id": "6370d45d-ca44-4fa0-a2d7-efaf0a207b91"
      },
      "source": [
        "\n",
        "Now let's check out what happens when we move data through `nn.MaxPool2d()`."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now we're going to create a sample MaxPool2d layer\n",
        "because remember even layers themselves in torch.nn are models of their own accord\n",
        "\n",
        "so we can just think this is like creating a single layer model here\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "we're going to print out the shape here this is just highlighting how i like to troubleshoot things is i do one step print the shape one step print the shape see what is happening as our data moves through various layers"
      ],
      "metadata": {
        "id": "055JJtEuaEeK"
      },
      "id": "055JJtEuaEeK"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "1164c753-19d9-43b7-a04f-017d0f7188c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1164c753-19d9-43b7-a04f-017d0f7188c3",
        "outputId": "b905dbcf-b37a-4310-fbcc-9d6f1f3b3422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test image original shape: torch.Size([3, 64, 64])\n",
            "Test image with unsqueezed dimension: torch.Size([1, 3, 64, 64])\n",
            "\n",
            "Shape after going through conv_layer(): torch.Size([1, 10, 62, 62])\n",
            "Shape after going through conv_layer() and max_pool_layer(): torch.Size([1, 10, 31, 31])\n"
          ]
        }
      ],
      "source": [
        "# Print out original image shape without and with unsqueezed dimension\n",
        "\n",
        "print(f\"Test image original shape: {test_image.shape}\")\n",
        "print(f\"Test image with unsqueezed dimension: {test_image.unsqueeze(dim=0).shape}\", end = '\\n\\n')\n",
        "\n",
        "# Create a sample nn.MaxPoo2d() layer\n",
        "\n",
        "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "# Pass data through just the conv_layer\n",
        "\n",
        "test_image_through_conv = conv_layer(test_image.unsqueeze(dim=0))\n",
        "print(f\"Shape after going through conv_layer(): {test_image_through_conv.shape}\")\n",
        "\n",
        "# Pass data through the max pool layer\n",
        "\n",
        "test_image_through_conv_and_max_pool = max_pool_layer(test_image_through_conv)\n",
        "print(f\"Shape after going through conv_layer() and max_pool_layer(): {test_image_through_conv_and_max_pool.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de029abd-6674-4bfa-99ab-322f339f89f4",
      "metadata": {
        "id": "de029abd-6674-4bfa-99ab-322f339f89f4"
      },
      "source": [
        "Notice the change in the shapes of what's happening in and out of a `nn.MaxPool2d()` layer.\n",
        "\n",
        "The `kernel_size` of the `nn.MaxPool2d()` layer will effects the **size** of the **output** **shape**.\n",
        "\n",
        "In our case, the shape halves from a `62x62` image to `31x31` image.\n",
        "\n",
        "Let's see this work with a smaller tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "e6a2b196-4845-4b40-9212-e75406e88875",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6a2b196-4845-4b40-9212-e75406e88875",
        "outputId": "a5ae043b-f25e-4c6f-f587-7b85514efdeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random tensor:\n",
            "tensor([[[[0.3367, 0.1288],\n",
            "          [0.2345, 0.2303]]]])\n",
            "Random tensor shape: torch.Size([1, 1, 2, 2])\n",
            "\n",
            "Max pool tensor:\n",
            "tensor([[[[0.3367]]]]) <- this is the maximum value from random_tensor\n",
            "Max pool tensor shape: torch.Size([1, 1, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Create a random tensor with a similiar number of dimensions to our images\n",
        "\n",
        "random_tensor = torch.randn(size=(1, 1, 2, 2))\n",
        "print(f\"Random tensor:\\n{random_tensor}\")\n",
        "print(f\"Random tensor shape: {random_tensor.shape}\")\n",
        "\n",
        "# Create a max pool layer\n",
        "max_pool_layer = nn.MaxPool2d(kernel_size=2) # see what happens when you change the kernel_size value\n",
        "\n",
        "# Pass the random tensor through the max pool layer\n",
        "\n",
        "max_pool_tensor = max_pool_layer(random_tensor)\n",
        "print(f\"\\nMax pool tensor:\\n{max_pool_tensor} <- this is the maximum value from random_tensor\")\n",
        "print(f\"Max pool tensor shape: {max_pool_tensor.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "002e586e-dcb3-40fe-a7dd-a1c18a3b8da0",
      "metadata": {
        "id": "002e586e-dcb3-40fe-a7dd-a1c18a3b8da0"
      },
      "source": [
        "Notice the final two dimensions between `random_tensor` and `max_pool_tensor`, they go from `[2, 2]` to `[1, 1]`.\n",
        "\n",
        "In essence, they get halved.\n",
        "\n",
        "And the change would be different for different values of `kernel_size` for `nn.MaxPool2d()`.\n",
        "\n",
        "Also notice the value leftover in `max_pool_tensor` is the **maximum** value from `random_tensor`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What's happening here?\n",
        "\n",
        "This is another important piece of the puzzle of neural networks.\n",
        "\n",
        "Essentially, **every layer in a neural network is trying to compress data from higher dimensional space to lower dimensional space**.\n",
        "\n",
        "In other words, take a lot of numbers (raw data) and learn patterns in those numbers, patterns that are predictive whilst also being *smaller* in size than the original values.\n",
        "\n",
        "From an artificial intelligence perspective, you could consider the whole goal of a neural network to *compress* information.\n",
        "\n",
        "![each layer of a neural network compresses the original input data into a smaller representation that is (hopefully) capable of making predictions on future input data](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-conv-net-as-compression.png)\n",
        "\n",
        "This means, that from the point of view of a neural network, intelligence is compression.\n",
        "\n",
        "This is the idea of the use of a `nn.MaxPool2d()` layer: take the maximum value from a portion of a tensor and disregard the rest.\n",
        "\n",
        "In essence, lowering the dimensionality of a tensor whilst still retaining a (hopefully) significant portion of the information.\n",
        "\n",
        "It is the same story for a `nn.Conv2d()` layer.\n",
        "\n",
        "Except instead of just taking the maximum, the `nn.Conv2d()` performs a convolutional operation on the data (see this in action on the [CNN Explainer webpage](https://poloclub.github.io/cnn-explainer/)).\n",
        "\n",
        "> **Exercise:** What do you think the [`nn.AvgPool2d()`](https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html) layer does? Try making a random tensor like we did above and passing it through. Check the input and output shapes as well as the input and output values.\n",
        "\n",
        "> **Extra-curriculum:** Lookup \"most common convolutional neural networks\", what architectures do you find? Are any of them contained within the [`torchvision.models`](https://pytorch.org/vision/stable/models.html) library? What do you think you could do with these?"
      ],
      "metadata": {
        "id": "vkes07wNbmIV"
      },
      "id": "vkes07wNbmIV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.3 Setup a loss function and optimizer for `model_2`\n"
      ],
      "metadata": {
        "id": "N52zWKc5a1Sp"
      },
      "id": "N52zWKc5a1Sp"
    },
    {
      "cell_type": "markdown",
      "id": "39a3c646-52f0-4f4b-8527-2fc33d0dfb13",
      "metadata": {
        "id": "39a3c646-52f0-4f4b-8527-2fc33d0dfb13"
      },
      "source": [
        "\n",
        "We've stepped through the layers in our first CNN enough.\n",
        "\n",
        "But remember, \\\n",
        "**if something still isn't clear, try starting small.**\n",
        "\n",
        "Pick a single layer of a model, pass some data through it and see what happens.\n",
        "\n",
        "Now it's time to move forward and get to training!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's setup a loss function and an optimizer.\n",
        "\n",
        "We'll use the functions as before, `nn.CrossEntropyLoss()` as the loss function (since we're working with multi-class classification data).\n",
        "\n",
        "And `torch.optim.SGD()` as the optimizer to optimize `model_2.parameters()` with a learning rate of `0.1`."
      ],
      "metadata": {
        "id": "n8p9utEicE34"
      },
      "id": "n8p9utEicE34"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "06a76a1b-5f6f-4018-bf7b-8388b385476f",
      "metadata": {
        "id": "06a76a1b-5f6f-4018-bf7b-8388b385476f"
      },
      "outputs": [],
      "source": [
        "# Setup loss and optimizer\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()  # cuz multi-class model\n",
        "optimizer = torch.optim.SGD(params=model_2.parameters(),\n",
        "                             lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.4 Training and testing `model_2` using our training and test functions"
      ],
      "metadata": {
        "id": "0QBeR16zg3nd"
      },
      "id": "0QBeR16zg3nd"
    },
    {
      "cell_type": "markdown",
      "id": "758bc223-a244-4604-a07a-e2fc2f96c2f6",
      "metadata": {
        "id": "758bc223-a244-4604-a07a-e2fc2f96c2f6"
      },
      "source": [
        "\n",
        "\n",
        "Loss and optimizer ready!\n",
        "\n",
        "Time to train and test.\n",
        "\n",
        "We'll use our `train_step()` and `test_step()` functions we created before.\n",
        "\n",
        "We'll also measure the time to compare it to our other models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "861d126e-d876-40b3-9b7a-66cfc2f1bf05",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327,
          "referenced_widgets": [
            "d4e1553bb6194369a4c4187a86b0da15",
            "8658f23f81bb4b579e6c19ac7aa664e9",
            "bdf2d474adce4a1bb596186c66af7eb9",
            "b732fd57cd6d400c994e43afffb075d1",
            "d2e0d81461774fb5a95c98634572c420",
            "531a793df18544b38070b146ba08bd95",
            "5ad22a9a37ac461b9d6b29c7ace90e5b",
            "8c8d2668e68a4bfc818732e72563108c",
            "e6873e8911064fe385c1b253f366c8e6",
            "cd70de1e99fa41afa1ea8453f89e960a",
            "5e44b6643d2340099b6d6c96c53c9918"
          ]
        },
        "id": "861d126e-d876-40b3-9b7a-66cfc2f1bf05",
        "outputId": "cc53fbd7-aa1a-4bf1-e9c2-7d84fd9c9397"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4e1553bb6194369a4c4187a86b0da15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "---------\n",
            "Train loss: 0.59222 | Train accuracy: 78.46%\n",
            "Test loss: 0.39803 | Test accuracy: 85.82%\n",
            "\n",
            "Epoch: 1\n",
            "---------\n",
            "Train loss: 0.36175 | Train accuracy: 86.96%\n",
            "Test loss: 0.34306 | Test accuracy: 87.36%\n",
            "\n",
            "Epoch: 2\n",
            "---------\n",
            "Train loss: 0.32297 | Train accuracy: 88.33%\n",
            "Test loss: 0.32921 | Test accuracy: 88.17%\n",
            "\n",
            "Train time on cuda: 36.232 seconds\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "#torch.cuda.manual_seed(42)\n",
        "\n",
        "# Measure time\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "train_time_start_model_2 = timer() # start timer\n",
        "\n",
        "# Train and test model\n",
        "epochs = 3\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    print(f\"Epoch: {epoch}\\n---------\")\n",
        "    train_step(data_loader=train_dataloader,\n",
        "        model=model_2,\n",
        "        loss_fn=loss_fn,\n",
        "        optimizer=optimizer,\n",
        "        accuracy_fn=accuracy_fn,\n",
        "        device=device\n",
        "    )\n",
        "    test_step(data_loader=test_dataloader,\n",
        "        model=model_2,\n",
        "        loss_fn=loss_fn,\n",
        "        accuracy_fn=accuracy_fn,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "\n",
        "train_time_end_model_2 = timer() # End timer\n",
        "\n",
        "total_train_time_model_2 = print_train_time(start=train_time_start_model_2,\n",
        "                                           end=train_time_end_model_2,\n",
        "                                           device=device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfec7b7e-4dba-4016-957a-a29c6c10fde0",
      "metadata": {
        "id": "cfec7b7e-4dba-4016-957a-a29c6c10fde0"
      },
      "source": [
        "Woah! Looks like the convolutional and max pooling layers helped improve performance a little.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's evaluate `model_2`'s results with our `eval_model()` function."
      ],
      "metadata": {
        "id": "WnYac0Ovhnkw"
      },
      "id": "WnYac0Ovhnkw"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "c1bf8b89-1389-4395-a1c4-9c6e94d9e71c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1bf8b89-1389-4395-a1c4-9c6e94d9e71c",
        "outputId": "af9c6803-fde1-404c-f0dd-8c060d8f6670"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_name': 'FashionMNISTModelV2',\n",
              " 'model_loss': 0.32921141386032104,\n",
              " 'model_acc': 88.16892971246007}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "# Get model_2 results\n",
        "\n",
        "model_2_results = eval_model(\n",
        "    model=model_2,\n",
        "    data_loader=test_dataloader,\n",
        "    loss_fn=loss_fn,\n",
        "    accuracy_fn=accuracy_fn\n",
        ")\n",
        "\n",
        "\n",
        "model_2_results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Compare model results and training time\n"
      ],
      "metadata": {
        "id": "RzWw7lpThqp6"
      },
      "id": "RzWw7lpThqp6"
    },
    {
      "cell_type": "markdown",
      "id": "24c5ff68-b0bc-4b09-9da6-696736bc262d",
      "metadata": {
        "id": "24c5ff68-b0bc-4b09-9da6-696736bc262d"
      },
      "source": [
        "\n",
        "We've trained three different models.\n",
        "\n",
        "1. `model_0` - our baseline model with two `nn.Linear()` layers.\n",
        "2. `model_1` - the same setup as our baseline model except with `nn.ReLU()` layers in between the `nn.Linear()` layers.\n",
        "3. `model_2` - our first CNN model that mimics the TinyVGG architecture on the CNN Explainer website.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a regular practice in machine learning.\n",
        "\n",
        "Building multiple models and performing multiple training experiments to see which performs best.\n",
        "\n",
        "**Let's combine our model results dictionaries into a DataFrame and find out.**"
      ],
      "metadata": {
        "id": "MPv-WDvxhuCc"
      },
      "id": "MPv-WDvxhuCc"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "52d84ee1-1ad4-4860-b147-f8912c1febc7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "52d84ee1-1ad4-4860-b147-f8912c1febc7",
        "outputId": "61cddc56-bbb5-4691-bbf8-6a54bcc58d25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            model_name  model_loss  model_acc\n",
              "0  FashionMNISTModelV0    0.476639  83.426518\n",
              "1  FashionMNISTModelV1    0.685001  75.019968\n",
              "2  FashionMNISTModelV2    0.329211  88.168930"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-148c7b5d-e002-49c0-b747-f3816d5d77b7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>model_loss</th>\n",
              "      <th>model_acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FashionMNISTModelV0</td>\n",
              "      <td>0.476639</td>\n",
              "      <td>83.426518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FashionMNISTModelV1</td>\n",
              "      <td>0.685001</td>\n",
              "      <td>75.019968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FashionMNISTModelV2</td>\n",
              "      <td>0.329211</td>\n",
              "      <td>88.168930</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-148c7b5d-e002-49c0-b747-f3816d5d77b7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-148c7b5d-e002-49c0-b747-f3816d5d77b7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-148c7b5d-e002-49c0-b747-f3816d5d77b7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-04ae8965-a017-47ae-9d11-0911ab5c8fbc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-04ae8965-a017-47ae-9d11-0911ab5c8fbc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-04ae8965-a017-47ae-9d11-0911ab5c8fbc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f5f1627a-7083-40fa-8b28-2278342a48dc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('compare_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f5f1627a-7083-40fa-8b28-2278342a48dc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('compare_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "compare_results",
              "summary": "{\n  \"name\": \"compare_results\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"model_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"FashionMNISTModelV0\",\n          \"FashionMNISTModelV1\",\n          \"FashionMNISTModelV2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1787622924392058,\n        \"min\": 0.32921141386032104,\n        \"max\": 0.6850008964538574,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.47663888335227966,\n          0.6850008964538574,\n          0.32921141386032104\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.659025711113401,\n        \"min\": 75.01996805111821,\n        \"max\": 88.16892971246007,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          83.42651757188499,\n          75.01996805111821,\n          88.16892971246007\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "import pandas as pd\n",
        "compare_results = pd.DataFrame([model_0_results, model_1_results, model_2_results])\n",
        "compare_results\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c67f3fb5-ce7b-40b8-86a0-2797492de0ef",
      "metadata": {
        "id": "c67f3fb5-ce7b-40b8-86a0-2797492de0ef"
      },
      "source": [
        "Nice!\n",
        "\n",
        "We can add the training time values too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "297af38f-e69f-4c6f-9027-fcaf0482a55c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "297af38f-e69f-4c6f-9027-fcaf0482a55c",
        "outputId": "9167b870-73b4-4736-b292-8bb19c57269e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            model_name  model_loss  model_acc  training_time\n",
              "0  FashionMNISTModelV0    0.476639  83.426518      42.339799\n",
              "1  FashionMNISTModelV1    0.685001  75.019968      32.291033\n",
              "2  FashionMNISTModelV2    0.329211  88.168930      36.232404"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bece6bf8-b69e-4fb9-84c4-a30426462c48\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>model_loss</th>\n",
              "      <th>model_acc</th>\n",
              "      <th>training_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FashionMNISTModelV0</td>\n",
              "      <td>0.476639</td>\n",
              "      <td>83.426518</td>\n",
              "      <td>42.339799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FashionMNISTModelV1</td>\n",
              "      <td>0.685001</td>\n",
              "      <td>75.019968</td>\n",
              "      <td>32.291033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FashionMNISTModelV2</td>\n",
              "      <td>0.329211</td>\n",
              "      <td>88.168930</td>\n",
              "      <td>36.232404</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bece6bf8-b69e-4fb9-84c4-a30426462c48')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bece6bf8-b69e-4fb9-84c4-a30426462c48 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bece6bf8-b69e-4fb9-84c4-a30426462c48');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d65f527f-0fc7-4719-94ed-8ab1a7d2f69d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d65f527f-0fc7-4719-94ed-8ab1a7d2f69d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d65f527f-0fc7-4719-94ed-8ab1a7d2f69d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_60ac328b-2f5a-4169-92c4-651a9ee46dbc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('compare_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_60ac328b-2f5a-4169-92c4-651a9ee46dbc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('compare_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "compare_results",
              "summary": "{\n  \"name\": \"compare_results\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"model_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"FashionMNISTModelV0\",\n          \"FashionMNISTModelV1\",\n          \"FashionMNISTModelV2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1787622924392058,\n        \"min\": 0.32921141386032104,\n        \"max\": 0.6850008964538574,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.47663888335227966,\n          0.6850008964538574,\n          0.32921141386032104\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.659025711113401,\n        \"min\": 75.01996805111821,\n        \"max\": 88.16892971246007,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          83.42651757188499,\n          75.01996805111821,\n          88.16892971246007\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"training_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.063140860648016,\n        \"min\": 32.291032761000025,\n        \"max\": 42.339798583000004,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          42.339798583000004,\n          32.291032761000025,\n          36.23240356900004\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "# Add training times to results comparison\n",
        "compare_results[\"training_time\"] = [total_train_time_model_0, # baseline\n",
        "                                    total_train_time_model_1, # non-linear\n",
        "                                    total_train_time_model_2] # TinyVGG\n",
        "compare_results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like our CNN (`FashionMNISTModelV2`) model performed the best (lowest loss, highest accuracy) but had the longest training time.\n",
        "\n",
        "And our baseline model (`FashionMNISTModelV0`) performed better than `model_1` (`FashionMNISTModelV1`)."
      ],
      "metadata": {
        "id": "GBOI7O5xh8W2"
      },
      "id": "GBOI7O5xh8W2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Performance-speed tradeoff\n"
      ],
      "metadata": {
        "id": "TG5990wZh9xq"
      },
      "id": "TG5990wZh9xq"
    },
    {
      "cell_type": "markdown",
      "id": "fbbe5832-1081-4c76-8d5b-06c7a06da7b9",
      "metadata": {
        "id": "fbbe5832-1081-4c76-8d5b-06c7a06da7b9"
      },
      "source": [
        "\n",
        "\n",
        "Something to be aware of in machine learning is the **performance-speed** tradeoff.\n",
        "\n",
        "Generally, you get better performance out of a larger, more complex model (like we did with `model_2`).\n",
        "\n",
        "However, this performance increase often comes at a sacrifice of training speed and inference speed.\n",
        "\n",
        "> **Note:** The training times you get will be very dependant on the hardware you use.\n",
        ">\n",
        "> Generally, the more CPU cores you have, the faster your models will train on CPU. And similar for GPUs.\n",
        ">\n",
        "> Newer hardware (in terms of age) will also often train models faster due to incorporating technology advances.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How about we get visual?"
      ],
      "metadata": {
        "id": "FD-z9hpIiVwz"
      },
      "id": "FD-z9hpIiVwz"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "5eb0df60-9318-47d0-adce-f8788ed3999e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "5eb0df60-9318-47d0-adce-f8788ed3999e",
        "outputId": "6e011ee1-5333-41cc-aae7-440b181d7805"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualize our model results\n",
        "\n",
        "compare_results.set_index(\"model_name\")[\"model_acc\"].plot(kind=\"barh\")\n",
        "\n",
        "plt.xlabel(\"accuracy (%)\")\n",
        "plt.ylabel(\"model\");"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Make and evaluate random predictions with best model\n"
      ],
      "metadata": {
        "id": "E4W_6LPSikPY"
      },
      "id": "E4W_6LPSikPY"
    },
    {
      "cell_type": "markdown",
      "id": "0ba50d51-adb3-4e49-9b9a-85173e747352",
      "metadata": {
        "id": "0ba50d51-adb3-4e49-9b9a-85173e747352"
      },
      "source": [
        "\n",
        "Alright, we've compared our models to each other,\n",
        "\n",
        "let's further evaluate our best performing model, `model_2`.\n",
        "\n",
        "To do so, let's create a function `make_predictions()` where we can pass the model and some data for it to predict on."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "just take random samples from the test data set \\\n",
        "make predictions on them using our model and then plot those predictions\n",
        "\n",
        "\n",
        "so this is only one way of doing things there are many different ways that you could make predictions and visualize them i'm just exemplifying one way"
      ],
      "metadata": {
        "id": "tn6CvgsQkiGx"
      },
      "id": "tn6CvgsQkiGx"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "d1d5d3e7-9601-4141-8bd7-9abbd016bf6c",
      "metadata": {
        "id": "d1d5d3e7-9601-4141-8bd7-9abbd016bf6c"
      },
      "outputs": [],
      "source": [
        "def make_predictions(model: torch.nn.Module, data: list, device: torch.device = device):\n",
        "\n",
        "    pred_probs = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for sample in data:\n",
        "            # Prepare sample\n",
        "            sample = torch.unsqueeze(sample, dim=0).to(device) # Add an extra dimension and send sample to device\n",
        "\n",
        "            # Forward pass (model outputs raw logit)\n",
        "            pred_logit = model(sample)\n",
        "\n",
        "            # Get prediction probability (logit -> prediction probability)\n",
        "            pred_prob = torch.softmax(pred_logit.squeeze(), dim=0) # note: perform softmax on the \"logits\" dimension, not \"batch\" dimension (in this case we have a batch size of 1, so can perform on dim=0)\n",
        "\n",
        "            # Get pred_prob off GPU for further calculations\n",
        "            pred_probs.append(pred_prob.cpu())\n",
        "\n",
        "    # Stack the pred_probs to turn list into a tensor\n",
        "    return torch.stack(pred_probs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "when we are evaluating predictions we want to compare them to the ground truth\n",
        "\n",
        "so we want to get some test samples and then we want to get their actual labels\n",
        "\n",
        "so that when our model makes predictions we can compare them to their actual labels"
      ],
      "metadata": {
        "id": "hCeAmvmnlNCC"
      },
      "id": "hCeAmvmnlNCC"
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "420c7461-eaa9-4459-9e68-53574c758765",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "420c7461-eaa9-4459-9e68-53574c758765",
        "outputId": "1260cc90-7577-4dcf-91a2-8f91fa841038"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test sample image shape: torch.Size([1, 28, 28])\n",
            "\n",
            " Test sample label: 5 (Sandal)\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "test_samples = []\n",
        "test_labels = []\n",
        "\n",
        "for sample, label in random.sample(list(test_data), k=9):\n",
        "    test_samples.append(sample)\n",
        "    test_labels.append(label)\n",
        "\n",
        "# View the first test sample shape and label\n",
        "\n",
        "print(f\"Test sample image shape: {test_samples[0].shape}\\n\\n Test sample label: {test_labels[0]} ({class_names[test_labels[0]]})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this is one of my favorite things to do i can't stress it enough is to randomly pick data samples from the test data set\n",
        "\n",
        "and predict on them and do it over and over and over again to see what the model is doing"
      ],
      "metadata": {
        "id": "FhNqWYCYltor"
      },
      "id": "FhNqWYCYltor"
    },
    {
      "cell_type": "markdown",
      "id": "e9f40dd9-7987-42a9-84cc-65dc912a6345",
      "metadata": {
        "id": "e9f40dd9-7987-42a9-84cc-65dc912a6345"
      },
      "source": [
        "And now we can use our `make_predictions()` function to predict on `test_samples`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "79de2ac1-7d4b-4f81-ae8a-90099bca2a3d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79de2ac1-7d4b-4f81-ae8a-90099bca2a3d",
        "outputId": "bbd2e241-fac6-457d-929b-f6d1154d77a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.3716e-06, 2.1327e-07, 9.7649e-07, 1.2922e-05, 4.4100e-07, 9.9951e-01,\n",
              "         8.1957e-06, 8.4949e-05, 1.5848e-04, 2.2321e-04],\n",
              "        [4.5386e-02, 6.3871e-01, 1.1731e-03, 1.6296e-01, 4.5598e-02, 4.9826e-04,\n",
              "         1.0195e-01, 1.8156e-03, 1.2615e-03, 6.4869e-04]])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "# Make predictions on test samples with model 2\n",
        "\n",
        "pred_probs= make_predictions(model=model_2,\n",
        "                             data=test_samples)\n",
        "\n",
        "# View first two prediction probabilities list\n",
        "pred_probs[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22d3c080-4eb6-4b5d-a5c4-2319e78228af",
      "metadata": {
        "id": "22d3c080-4eb6-4b5d-a5c4-2319e78228af"
      },
      "source": [
        "Excellent!\n",
        "so how do we convert prediction probabilities into labels\n",
        "\n",
        "\n",
        "And now we can go from prediction probabilities to prediction labels by taking the `torch.argmax()` of the output of the `torch.softmax()` activation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "f9d97bcc-4310-4851-a1f8-6bcd757e9b26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9d97bcc-4310-4851-a1f8-6bcd757e9b26",
        "outputId": "d8bafddf-1675-4504-f06d-d12d07463035"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 1, 7, 4, 3, 0, 4, 7, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "# Turn the prediction probabilities into prediction labels by taking the argmax()\n",
        "pred_classes = pred_probs.argmax(dim=1)\n",
        "pred_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "1141af97-0990-4920-83d4-c13cca3f9abc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1141af97-0990-4920-83d4-c13cca3f9abc",
        "outputId": "cf69ee3c-e01d-4731-a2a1-63e642a4a8e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([5, 1, 7, 4, 3, 0, 4, 7, 1], tensor([5, 1, 7, 4, 3, 0, 4, 7, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "# Are our predictions in the same form as our test labels?\n",
        "\n",
        "test_labels, pred_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ea04387-c9ad-424f-8297-defd7b685683",
      "metadata": {
        "id": "4ea04387-c9ad-424f-8297-defd7b685683"
      },
      "source": [
        "Now our predicted classes are in the same format as our test labels, we can compare.\n",
        "\n",
        "Since we're dealing with image data, let's stay true to the data explorer's motto.\n",
        "\n",
        "\"Visualize, visualize, visualize!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "679cb5f7-bb66-42dd-a4d6-400b27b7c019",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "679cb5f7-bb66-42dd-a4d6-400b27b7c019",
        "outputId": "0487590a-76fd-4283-fe61-2593e1ac5568"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x900 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot predictions\n",
        "\n",
        "plt.figure(figsize=(9, 9))\n",
        "\n",
        "nrows = 3\n",
        "ncols = 3\n",
        "\n",
        "for i, sample in enumerate(test_samples):\n",
        "\n",
        "  # Create a subplot for each looping\n",
        "  plt.subplot(nrows, ncols, i+1)\n",
        "\n",
        "  # Plot the target image\n",
        "  plt.imshow(sample.squeeze(), cmap=\"gray\")\n",
        "\n",
        "  # Find the prediction label (in text form, e.g. \"Sandal\")\n",
        "  pred_label = class_names[pred_classes[i]]\n",
        "\n",
        "  # Get the truth label (in text form, e.g. \"T-shirt\")\n",
        "  truth_label = class_names[test_labels[i]]\n",
        "\n",
        "  # Create the title text of the plot DYNAMICALLY\n",
        "  title_text = f\"Pred: {pred_label} | Truth: {truth_label}\"\n",
        "\n",
        "  # Check for equality and change title colour accordingly\n",
        "  if pred_label == truth_label:\n",
        "      plt.title(title_text, fontsize=10, c=\"g\") # green text if correct\n",
        "  else:\n",
        "      plt.title(title_text, fontsize=10, c=\"r\") # red text if wrong\n",
        "  plt.axis(False);\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ce6dc44-90a5-48c3-91a5-810fa084d98b",
      "metadata": {
        "id": "5ce6dc44-90a5-48c3-91a5-810fa084d98b"
      },
      "source": [
        "Well, well, well, doesn't that look good!\n",
        "\n",
        "Not bad for a couple dozen lines of PyTorch code!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The thing to note here is\n",
        "\n",
        "what you'll find in a lot of data sets especially quite large ones just for the sheer lore of large numbers there may be some truth labels in your data sets that you work with that are wrong and so that's why i like to see compare the models predictions versus the truth on a bunch of random samples to know\n",
        "\n",
        "what is our model's results better or worse than they actually are and that's what visualizing helps you do is figure out you know what our model actually  says\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6dgaHD-inPjQ"
      },
      "id": "6dgaHD-inPjQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Making a confusion matrix for further prediction evaluation\n"
      ],
      "metadata": {
        "id": "N-2dtxAsjAtq"
      },
      "id": "N-2dtxAsjAtq"
    },
    {
      "cell_type": "markdown",
      "id": "ab108078-6770-4cb9-ac62-a761ff159aba",
      "metadata": {
        "id": "ab108078-6770-4cb9-ac62-a761ff159aba"
      },
      "source": [
        "\n",
        "There are many [different evaluation metrics](https://www.learnpytorch.io/02_pytorch_classification/#9-more-classification-evaluation-metrics) we can use for classification problems.\n",
        "\n",
        "One of the most visual is a [confusion matrix](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/).\n",
        "\n",
        "A confusion matrix shows you where your classification model got confused between predicitons and true labels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make a confusion matrix, we'll go through three steps:\n",
        "1. Make predictions with our trained model, `model_2` (a confusion matrix compares predictions to true labels).\n",
        "2. Make a confusion matrix using [`torchmetrics.ConfusionMatrix`](https://torchmetrics.readthedocs.io/en/latest/references/modules.html?highlight=confusion#confusionmatrix).\n",
        "\n",
        "Torchmetrics is built on pytorch\n",
        "\n",
        "3. Plot the confusion matrix using [`mlxtend.plotting.plot_confusion_matrix()`](http://rasbt.github.io/mlxtend/user_guide/plotting/plot_confusion_matrix/).\n",
        "\n",
        "Sebastian Raschka created above package\n"
      ],
      "metadata": {
        "id": "GeALqsVp_GPE"
      },
      "id": "GeALqsVp_GPE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let's start by making predictions with our trained model across the whole test dataset\n"
      ],
      "metadata": {
        "id": "BJ8c3jdA_nq9"
      },
      "id": "BJ8c3jdA_nq9"
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "065b8090-c9c5-43df-b5c1-b45ba33af1be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c740b6a106eb44bba50f1ee8cf257d33",
            "5c9fe7d5827f495caab8a4a860c8708b",
            "7a81c785a703492098238d504203f26f",
            "e1c03b47f80348968e7adf574347a4fd",
            "807db11d9c644e9fa0e79c246b5bfe02",
            "456ba8ca970841e896ed330abfb1f50d",
            "a153a51c5b1b45ce9d0d6a8ce3c2cd01",
            "f7c4e6bae7e54762ae8a827537af1dfc",
            "c2254e1cdd1442bc88ee9b25723e2f56",
            "8591c220372543a083b58c594db8476c",
            "a08c193d95844fbaa1a794e64e42d2a9"
          ]
        },
        "id": "065b8090-c9c5-43df-b5c1-b45ba33af1be",
        "outputId": "e84ce9ca-892e-4581-df1d-9374bafc4356"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Making predictions:   0%|          | 0/313 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c740b6a106eb44bba50f1ee8cf257d33"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Import tqdm for progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# 1. Make predictions with trained model\n",
        "\n",
        "y_preds = []\n",
        "model_2.eval()\n",
        "\n",
        "with torch.inference_mode():\n",
        "\n",
        "  for X, y in tqdm(test_dataloader, desc=\"Making predictions\"):\n",
        "\n",
        "    # Send data and targets to target device\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # Do the forward pass\n",
        "    y_logit = model_2(X)\n",
        "\n",
        "    # Turn predictions from logits -> prediction probabilities -> predictions labels\n",
        "    y_pred = torch.softmax(y_logit, dim=1).argmax(dim=1) # note: perform softmax on the \"logits\" dimension, not \"batch\" dimension (in this case we have a batch size of 32, so can perform on dim=1)\n",
        "\n",
        "    # Put predictions on CPU for evaluation\n",
        "    y_preds.append(y_pred.cpu())\n",
        "\n",
        "# Concatenate list of predictions into a tensor\n",
        "y_pred_tensor = torch.cat(y_preds)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "362002d9-ec41-4c74-a210-b5d4f53410c4",
      "metadata": {
        "id": "362002d9-ec41-4c74-a210-b5d4f53410c4"
      },
      "source": [
        "Wonderful!\n",
        "\n",
        "Now we've got predictions, let's go through steps 2 & 3:\n",
        "2. Make a confusion matrix using [`torchmetrics.ConfusionMatrix`](https://torchmetrics.readthedocs.io/en/latest/references/modules.html?highlight=confusion#confusionmatrix).\n",
        "3. Plot the confusion matrix using [`mlxtend.plotting.plot_confusion_matrix()`](http://rasbt.github.io/mlxtend/user_guide/plotting/plot_confusion_matrix/).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we'll need to make sure we've got `torchmetrics` and `mlxtend` installed (these two libraries will help us make and visual a confusion matrix).\n",
        "\n",
        "> **Note:** If you're using Google Colab, the default version of `mlxtend` installed is 0.14.0 (as of March 2022), however, for the parameters of the `plot_confusion_matrix()` function we'd like use, we need 0.19.0 or higher."
      ],
      "metadata": {
        "id": "JEOWphPk_5e-"
      },
      "id": "JEOWphPk_5e-"
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "e6c0a05d-d3e0-4b86-9ef7-ee6ea5629b07",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6c0a05d-d3e0-4b86-9ef7-ee6ea5629b07",
        "outputId": "50e43136-08c8-432f-86cc-e2210b56e983"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/866.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m860.2/866.2 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.2/866.2 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hmlxtend version: 0.23.1\n"
          ]
        }
      ],
      "source": [
        "# See if torchmetrics exists, if not, install it\n",
        "\n",
        "try:\n",
        "    import torchmetrics, mlxtend\n",
        "    print(f\"mlxtend version: {mlxtend.__version__}\")\n",
        "    assert int(mlxtend.__version__.split(\".\")[1]) >= 19, \"mlxtend verison should be 0.19.0 or higher\"\n",
        "except:\n",
        "    !pip install -q torchmetrics -U mlxtend # <- Note: If you're using Google Colab, this may require restarting the runtime\n",
        "    import torchmetrics, mlxtend\n",
        "    print(f\"mlxtend version: {mlxtend.__version__}\")\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5245ede6-fd7f-40ad-a0b3-ae678544b84a",
      "metadata": {
        "id": "5245ede6-fd7f-40ad-a0b3-ae678544b84a"
      },
      "source": [
        "To plot the confusion matrix, we need to make sure we've got and [`mlxtend`](http://rasbt.github.io/mlxtend/) version of 0.19.0 or higher."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "21383f88-a2dd-4678-94c6-479c592da0ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21383f88-a2dd-4678-94c6-479c592da0ab",
        "outputId": "23b65d61-5e72-4182-d035-cbce176dd69b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.23.1\n"
          ]
        }
      ],
      "source": [
        "# Import mlxtend upgraded version\n",
        "\n",
        "import mlxtend\n",
        "print(mlxtend.__version__)\n",
        "\n",
        "assert int(mlxtend.__version__.split(\".\")[1]) >= 19 # should be version 0.19.0 or higher"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c91b9346-e25f-48ab-967e-425649331dc6",
      "metadata": {
        "id": "c91b9346-e25f-48ab-967e-425649331dc6"
      },
      "source": [
        "`torchmetrics` and `mlxtend` installed, let's make a confusion matrix!\n",
        "\n",
        "First we'll create a `torchmetrics.ConfusionMatrix` instance telling it how many classes we're dealing with by setting `num_classes=len(class_names)`.\n",
        "\n",
        "Then we'll create a confusion matrix (in tensor format) by passing \\\n",
        "our instance our model's predictions (`preds=y_pred_tensor`) and targets (`target=test_data.targets`).\n",
        "\n",
        "Finally we can plot our confusion matrix using the `plot_confusion_matrix()` function from `mlxtend.plotting`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "7aed6d76-ad1c-429e-b8e0-c80572e3ebf4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "7aed6d76-ad1c-429e-b8e0-c80572e3ebf4",
        "outputId": "96b010f3-4e61-4179-b84a-fcea24d6cb5b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from torchmetrics import ConfusionMatrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "# 2. Setup confusion matrix instance and compare predictions to targets\n",
        "\n",
        "confmat = ConfusionMatrix(num_classes=len(class_names), task='multiclass')\n",
        "confmat_tensor = confmat(preds=y_pred_tensor,\n",
        "                         target=test_data.targets)\n",
        "\n",
        "\n",
        "# 3. Plot the confusion matrix\n",
        "\n",
        "fig, ax = plot_confusion_matrix(\n",
        "    conf_mat = confmat_tensor.numpy(), # matplotlib likes working with NumPy\n",
        "    class_names = class_names, # turn the row and column labels into class names\n",
        "    figsize=(10, 7)\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Woah! Doesn't that look good?\n",
        "\n",
        "We can see our model does fairly well since most of the dark squares are down the diagonal from top left to bottom right\n",
        "\n",
        "and ideal model will have only values in these squares and 0 everywhere else.\n"
      ],
      "metadata": {
        "id": "2qXRJ3nuCBNi"
      },
      "id": "2qXRJ3nuCBNi"
    },
    {
      "cell_type": "markdown",
      "id": "381c1c93-df30-451c-b65e-5d4c1680dc30",
      "metadata": {
        "id": "381c1c93-df30-451c-b65e-5d4c1680dc30"
      },
      "source": [
        "\n",
        "The model gets most \"confused\" on classes that are similar, for example predicting \"Pullover\" for images that are actually labelled \"Shirt\".\n",
        "\n",
        "And the same for predicting \"Shirt\" for classes that are actually labelled \"T-shirt/top\".\n",
        "\n",
        "This kind of information is often more helpful than a single accuracy metric because it tells use *where* a model is getting things wrong.\n",
        "\n",
        "It also hints at *why* the model may be getting certain things wrong.\n",
        "\n",
        "It's understandable the model sometimes predicts \"Shirt\" for images labelled \"T-shirt/top\".\n",
        "\n",
        "We can use this kind of information to further inspect our models and data to see how it could be improved.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "so this is just a way to further evaluate your model\n",
        "\n",
        "and start to go hmm maybe our labels are a little bit confusing could we expand them a little bit more"
      ],
      "metadata": {
        "id": "QkGwdsLJCoW5"
      },
      "id": "QkGwdsLJCoW5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> **Exercise:**\n",
        "\n",
        "Use the trained `model_2` (non-linear model) to make predictions on the test FashionMNIST dataset. Then plot some predictions where the model was wrong alongside what the label of the image should've been.\n",
        "\n",
        "After visualing these predictions do you think it's more of a modelling error or a data error?\n",
        "\n",
        "As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
      ],
      "metadata": {
        "id": "97Q2moDvCK9y"
      },
      "id": "97Q2moDvCK9y"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Save and load best performing model\n"
      ],
      "metadata": {
        "id": "_sgEh8iTjDvj"
      },
      "id": "_sgEh8iTjDvj"
    },
    {
      "cell_type": "markdown",
      "id": "25818e83-89de-496d-8b56-af4fc9f2acc5",
      "metadata": {
        "id": "25818e83-89de-496d-8b56-af4fc9f2acc5"
      },
      "source": [
        "\n",
        "Let's finish this section off by saving and loading in our best performing model.\n",
        "\n",
        "Recall from [notebook 01](https://www.learnpytorch.io/01_pytorch_workflow/#5-saving-and-loading-a-pytorch-model) we can save and load a PyTorch model using a combination of:\n",
        "* `torch.save` - a function to save a whole PyTorch model or a model's `state_dict()`.\n",
        "* `torch.load` - a function to load in a saved PyTorch object.\n",
        "* `torch.nn.Module.load_state_dict()` - a function to load a saved `state_dict()` into an existing model instance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see more of these three in the [PyTorch saving and loading models documentation](https://pytorch.org/tutorials/beginner/saving_loading_models.html).\n",
        "\n",
        "For now, let's save our `model_2`'s `state_dict()`\n",
        "then load it back in and evaluate it to make sure the save and load went correctly.\n",
        "\n",
        "Recall state_dict(), \\\n",
        "has models all learned parameters i.e. weights and biases on the dataset\n"
      ],
      "metadata": {
        "id": "rx3TgkjiDCUs"
      },
      "id": "rx3TgkjiDCUs"
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "d058e8fa-560f-4350-a154-49593ff403c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d058e8fa-560f-4350-a154-49593ff403c9",
        "outputId": "6494be03-9b65-42ed-d991-e3062794252b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to: models/03_pytorch_computer_vision_model_2.pth\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Create models directory (if it doesn't already exist), see: https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, # create parent directories if needed\n",
        "                 exist_ok=True # if models directory already exists, don't error\n",
        ")\n",
        "\n",
        "# Create model save path\n",
        "MODEL_NAME = \"03_pytorch_computer_vision_model_2.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME # this is not division symbol, it is / for paths\n",
        "\n",
        "# Save the model state dict\n",
        "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=model_2.state_dict(), # only saving the state_dict() only saves the learned parameters\n",
        "           f=MODEL_SAVE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1542284-8132-42ba-b00d-57e9b9037e4e",
      "metadata": {
        "id": "a1542284-8132-42ba-b00d-57e9b9037e4e"
      },
      "source": [
        "Now we've got a saved model `state_dict()` we can load it back in using a combination of `load_state_dict()` and `torch.load()`.\n",
        "\n",
        "Since we're using `load_state_dict()`, we'll need to create a new instance of `FashionMNISTModelV2()` with the same input parameters as our saved model `state_dict()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "634a8f7a-3013-4b45-b365-49b286d3c478",
      "metadata": {
        "id": "634a8f7a-3013-4b45-b365-49b286d3c478"
      },
      "outputs": [],
      "source": [
        "# Create a new instance of FashionMNISTModelV2 (the same class as our saved state_dict())\n",
        "# Note: loading model will error if the parameters are not same as saved model cuz shapes won't be the same\n",
        "\n",
        "loaded_model_2 = FashionMNISTModelV2(input_shape=1,\n",
        "                                    hidden_units=10, # try changing this to 128 and seeing what happens\n",
        "                                    output_shape=10)\n",
        "\n",
        "# Load in the saved state_dict()\n",
        "loaded_model_2.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
        "\n",
        "# Send model to GPU\n",
        "loaded_model_2 = loaded_model_2.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feeaebf4-6040-4fa5-852d-5eb8d2bbb94c",
      "metadata": {
        "id": "feeaebf4-6040-4fa5-852d-5eb8d2bbb94c"
      },
      "source": [
        "And now we've got a loaded model we can evaluate it with `eval_model()` to make sure its parameters work similarly to `model_2` prior to saving."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "3e3bcd06-d99b-47bc-8828-9e3903285599",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e3bcd06-d99b-47bc-8828-9e3903285599",
        "outputId": "f232cc9b-ea9c-4fbe-b4e7-2f4509968a45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_name': 'FashionMNISTModelV2',\n",
              " 'model_loss': 0.32921141386032104,\n",
              " 'model_acc': 88.16892971246007}"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "# Evaluate loaded model\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "loaded_model_2_results = eval_model(\n",
        "    model=loaded_model_2,\n",
        "    data_loader=test_dataloader,\n",
        "    loss_fn=loss_fn,\n",
        "    accuracy_fn=accuracy_fn\n",
        ")\n",
        "\n",
        "loaded_model_2_results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "so this is what we're looking for we want to make sure that our saved model saved these results pretty closely\n",
        "\n",
        "now i say pretty closely because you might find some discrepancies in r these lower decimals here just because of the way files get saved and something gets lost etc etc\n",
        "\n",
        "so that's just to do with precision and computing but as long as like the first few numbers are quite similar well then we're all good\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7FAqcqSEFadY"
      },
      "id": "7FAqcqSEFadY"
    },
    {
      "cell_type": "markdown",
      "id": "c2b37855-c0da-4834-a2d4-a0faa8410b65",
      "metadata": {
        "id": "c2b37855-c0da-4834-a2d4-a0faa8410b65"
      },
      "source": [
        "Do these results look the same as `model_2_results`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "68544254-c99a-47ec-a32f-9816c21a993e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68544254-c99a-47ec-a32f-9816c21a993e",
        "outputId": "432a5d15-0e42-4f86-a2a5-4513b1a25fc2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_name': 'FashionMNISTModelV2',\n",
              " 'model_loss': 0.32921141386032104,\n",
              " 'model_acc': 88.16892971246007}"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "model_2_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ee07f93-4344-4c7a-8b1d-92a56034e7b2",
      "metadata": {
        "id": "0ee07f93-4344-4c7a-8b1d-92a56034e7b2"
      },
      "source": [
        "We can find out if two tensors are close to each other using `torch.isclose()` and passing in a tolerance level of closeness via the parameters `atol` (absolute tolerance) and `rtol` (relative tolerance).\n",
        "\n",
        "\n",
        "\n",
        "If our model's results are close, the output of `torch.isclose()` should be true."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "48dcf0ba-7e00-4406-8aaa-41918856361a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48dcf0ba-7e00-4406-8aaa-41918856361a",
        "outputId": "71d2cddb-1e5f-4529-a2e0-9daa94efe430"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "# Check to see if results are close to each other (if they are very far away, there may be an error)\n",
        "\n",
        "torch.isclose(torch.tensor(model_2_results[\"model_loss\"]), # turn into Tensor\n",
        "              torch.tensor(loaded_model_2_results[\"model_loss\"]), # turn into Tensor\n",
        "              atol=1e-08, # absolute tolerance -- decimal places\n",
        "              rtol=0.0001) # relative tolerance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3969b7d-9955-4b6f-abf8-fe8eedf233a9",
      "metadata": {
        "id": "c3969b7d-9955-4b6f-abf8-fe8eedf233a9"
      },
      "source": [
        "## Exercises\n",
        "\n",
        "All of the exercises are focused on practicing the code in the sections above.\n",
        "\n",
        "You should be able to complete them by referencing each section or by following the resource(s) linked.\n",
        "\n",
        "All exercises should be completed using [device-agnostic code](https://pytorch.org/docs/stable/notes/cuda.html#device-agnostic-code).\n",
        "\n",
        "**Resources:**\n",
        "* [Exercise template notebook for 03](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/03_pytorch_computer_vision_exercises.ipynb)\n",
        "* [Example solutions notebook for 03](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/03_pytorch_computer_vision_exercise_solutions.ipynb) (try the exercises *before* looking at this)\n",
        "\n",
        "1. What are 3 areas in industry where computer vision is currently being used?\n",
        "2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find.\n",
        "3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each. **Note:** there are lots of these, so don't worry too much about all of them, just pick 3 and start with those.\n",
        "4. Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
        "    * Upload your own example image using the \"upload\" button and see what happens in each layer of a CNN as your image passes through it.\n",
        "5. Load the [`torchvision.datasets.MNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) train and test datasets.\n",
        "6. Visualize at least 5 different samples of the MNIST training dataset.\n",
        "7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`.\n",
        "8. Recreate `model_2` used in this notebook (the same model from the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/), also known as TinyVGG) capable of fitting on the MNIST dataset.\n",
        "9. Train the model you built in exercise 8. on CPU and GPU and see how long it takes on each.\n",
        "10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label.\n",
        "11. Plot a confusion matrix comparing your model's predictions to the truth labels.\n",
        "12. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?\n",
        "13. Use a model similar to the trained `model_2` from this notebook to make predictions on the test [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html) dataset.\n",
        "    * Then plot some predictions where the model was wrong alongside what the label of the image should've been.\n",
        "    * After visualing these predictions do you think it's more of a modelling error or a data error?\n",
        "    * As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?\n",
        "\n",
        "## Extra-curriculum\n",
        "* **Watch:** [MIT's Introduction to Deep Computer Vision](https://www.youtube.com/watch?v=iaSUYvmCekI&list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&index=3) lecture. This will give you a great intuition behind convolutional neural networks.\n",
        "* Spend 10-minutes clicking thorugh the different options of the [PyTorch vision library](https://pytorch.org/vision/stable/index.html), what different modules are available?\n",
        "* Lookup \"most common convolutional neural networks\", what architectures do you find? Are any of them contained within the [`torchvision.models`](https://pytorch.org/vision/stable/models.html) library? What do you think you could do with these?\n",
        "* For a large number of pretrained PyTorch computer vision models as well as many different extensions to PyTorch's computer vision functionalities check out the [PyTorch Image Models library `timm`](https://github.com/rwightman/pytorch-image-models/) (Torch Image Models) by Ross Wightman."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "3fbe1355223f7b2ffc113ba3ade6a2b520cadace5d5ec3e828c83ce02eb221bf"
      }
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "91a4ae15fca94112998a102bbadab183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5672ef5a4dd4341b5cbfd0a70981e57",
              "IPY_MODEL_f717e46a25fe49b1b95d18b6fc8d9a19",
              "IPY_MODEL_9048827e1faf4a36bdd27c65d2c13583"
            ],
            "layout": "IPY_MODEL_6e071c51293a4bce87d86f5ee58266f5"
          }
        },
        "d5672ef5a4dd4341b5cbfd0a70981e57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b643e4b479d4791b7d6b536a0474c23",
            "placeholder": "​",
            "style": "IPY_MODEL_30191705727c45c8bb8b5ea49fc0bc62",
            "value": "100%"
          }
        },
        "f717e46a25fe49b1b95d18b6fc8d9a19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd38b144c0e14821aa8f77a201ccd980",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45f81dd710214e839bb813c30b990d08",
            "value": 3
          }
        },
        "9048827e1faf4a36bdd27c65d2c13583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f235274904143a0872b5747c78114c8",
            "placeholder": "​",
            "style": "IPY_MODEL_fc5efe6c6e16471cb282ed2c401d6fdb",
            "value": " 3/3 [00:42&lt;00:00, 14.67s/it]"
          }
        },
        "6e071c51293a4bce87d86f5ee58266f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b643e4b479d4791b7d6b536a0474c23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30191705727c45c8bb8b5ea49fc0bc62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd38b144c0e14821aa8f77a201ccd980": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45f81dd710214e839bb813c30b990d08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f235274904143a0872b5747c78114c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc5efe6c6e16471cb282ed2c401d6fdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53f8c4337921437da979586c8eb56e95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5129f06c7cce4356b1ecb4fa67f5f619",
              "IPY_MODEL_9a7d2a0325e541a1acbbd50759e7013d",
              "IPY_MODEL_77ad84a6f6354a489cb43ee5478537d0"
            ],
            "layout": "IPY_MODEL_0bb71cccac79480d8d9ce27087ebc87f"
          }
        },
        "5129f06c7cce4356b1ecb4fa67f5f619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d997a523b7043e88f12fb7ec06d7fe5",
            "placeholder": "​",
            "style": "IPY_MODEL_3f988ee23d354c4bbe386b2c4c269c31",
            "value": "100%"
          }
        },
        "9a7d2a0325e541a1acbbd50759e7013d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_daf6bca7910c48a7abf11e2ff742a554",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32fcc20dd34d49548c86049c504c222f",
            "value": 3
          }
        },
        "77ad84a6f6354a489cb43ee5478537d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce69abf81f3647d0943642b27f2cca17",
            "placeholder": "​",
            "style": "IPY_MODEL_ff990c9cde454e7e828b0e8b085fb682",
            "value": " 3/3 [00:32&lt;00:00, 10.85s/it]"
          }
        },
        "0bb71cccac79480d8d9ce27087ebc87f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d997a523b7043e88f12fb7ec06d7fe5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f988ee23d354c4bbe386b2c4c269c31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "daf6bca7910c48a7abf11e2ff742a554": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32fcc20dd34d49548c86049c504c222f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce69abf81f3647d0943642b27f2cca17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff990c9cde454e7e828b0e8b085fb682": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4e1553bb6194369a4c4187a86b0da15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8658f23f81bb4b579e6c19ac7aa664e9",
              "IPY_MODEL_bdf2d474adce4a1bb596186c66af7eb9",
              "IPY_MODEL_b732fd57cd6d400c994e43afffb075d1"
            ],
            "layout": "IPY_MODEL_d2e0d81461774fb5a95c98634572c420"
          }
        },
        "8658f23f81bb4b579e6c19ac7aa664e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_531a793df18544b38070b146ba08bd95",
            "placeholder": "​",
            "style": "IPY_MODEL_5ad22a9a37ac461b9d6b29c7ace90e5b",
            "value": "100%"
          }
        },
        "bdf2d474adce4a1bb596186c66af7eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c8d2668e68a4bfc818732e72563108c",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6873e8911064fe385c1b253f366c8e6",
            "value": 3
          }
        },
        "b732fd57cd6d400c994e43afffb075d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd70de1e99fa41afa1ea8453f89e960a",
            "placeholder": "​",
            "style": "IPY_MODEL_5e44b6643d2340099b6d6c96c53c9918",
            "value": " 3/3 [00:36&lt;00:00, 11.99s/it]"
          }
        },
        "d2e0d81461774fb5a95c98634572c420": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "531a793df18544b38070b146ba08bd95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ad22a9a37ac461b9d6b29c7ace90e5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c8d2668e68a4bfc818732e72563108c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6873e8911064fe385c1b253f366c8e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd70de1e99fa41afa1ea8453f89e960a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e44b6643d2340099b6d6c96c53c9918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c740b6a106eb44bba50f1ee8cf257d33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c9fe7d5827f495caab8a4a860c8708b",
              "IPY_MODEL_7a81c785a703492098238d504203f26f",
              "IPY_MODEL_e1c03b47f80348968e7adf574347a4fd"
            ],
            "layout": "IPY_MODEL_807db11d9c644e9fa0e79c246b5bfe02"
          }
        },
        "5c9fe7d5827f495caab8a4a860c8708b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_456ba8ca970841e896ed330abfb1f50d",
            "placeholder": "​",
            "style": "IPY_MODEL_a153a51c5b1b45ce9d0d6a8ce3c2cd01",
            "value": "Making predictions: 100%"
          }
        },
        "7a81c785a703492098238d504203f26f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7c4e6bae7e54762ae8a827537af1dfc",
            "max": 313,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2254e1cdd1442bc88ee9b25723e2f56",
            "value": 313
          }
        },
        "e1c03b47f80348968e7adf574347a4fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8591c220372543a083b58c594db8476c",
            "placeholder": "​",
            "style": "IPY_MODEL_a08c193d95844fbaa1a794e64e42d2a9",
            "value": " 313/313 [00:03&lt;00:00, 194.68it/s]"
          }
        },
        "807db11d9c644e9fa0e79c246b5bfe02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "456ba8ca970841e896ed330abfb1f50d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a153a51c5b1b45ce9d0d6a8ce3c2cd01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7c4e6bae7e54762ae8a827537af1dfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2254e1cdd1442bc88ee9b25723e2f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8591c220372543a083b58c594db8476c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a08c193d95844fbaa1a794e64e42d2a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}